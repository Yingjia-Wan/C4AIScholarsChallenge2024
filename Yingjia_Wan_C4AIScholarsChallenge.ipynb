{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_tjokNL8DVD2",
        "67d4055d-bb2d-49c7-a7e1-7f53fdb49658",
        "62103e4d-e1b3-4687-a30a-65842ae1b8a9",
        "d8d4fc28-1962-4f42-9378-22a683f4978d",
        "F1Yhn1yz6hMl"
      ],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ffad28e7766648cca2ccb879ac15d6fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_739ccf6e14f34468915df2644705df8f",
              "IPY_MODEL_f3177c05ab8a45ca8fd5e4fa0b255760",
              "IPY_MODEL_5fb87059d6444393baafbcd5409e883f"
            ],
            "layout": "IPY_MODEL_4ebf349fe6944de2a9da0eb7d4c9b11a"
          }
        },
        "739ccf6e14f34468915df2644705df8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83bf34d731c44b3190f45138899140a8",
            "placeholder": "​",
            "style": "IPY_MODEL_23c3cd696ad948108d298046f1a57228",
            "value": "Map: 100%"
          }
        },
        "f3177c05ab8a45ca8fd5e4fa0b255760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9003c3bf1ccf44fb869fc8eaeb0107fa",
            "max": 19823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ad40792bbe44bacaf4af4c16ec35cb8",
            "value": 19823
          }
        },
        "5fb87059d6444393baafbcd5409e883f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa454a705154639a5f21f062d9dd35f",
            "placeholder": "​",
            "style": "IPY_MODEL_5012179bc2044e1e8c51b560b914616b",
            "value": " 19823/19823 [00:02&lt;00:00, 5678.19 examples/s]"
          }
        },
        "4ebf349fe6944de2a9da0eb7d4c9b11a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83bf34d731c44b3190f45138899140a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c3cd696ad948108d298046f1a57228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9003c3bf1ccf44fb869fc8eaeb0107fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ad40792bbe44bacaf4af4c16ec35cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2aa454a705154639a5f21f062d9dd35f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5012179bc2044e1e8c51b560b914616b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b31badbfcf64cb0a63cbbe5d16190a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e34a15ee516464288245fca71db2006",
              "IPY_MODEL_7f3ea23a0c854ca689c1d4ce76eeab5c",
              "IPY_MODEL_a21642adbb644231a52d88d1f48c4c98"
            ],
            "layout": "IPY_MODEL_b0a74e7ce090458cbab71ef948dcf516"
          }
        },
        "3e34a15ee516464288245fca71db2006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3422b63c24194145a95b31e1151bafd1",
            "placeholder": "​",
            "style": "IPY_MODEL_608daa49e3194040ab34d876305c39c1",
            "value": "Map: 100%"
          }
        },
        "7f3ea23a0c854ca689c1d4ce76eeab5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56b77a010aa441059705a26548b9f735",
            "max": 485,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc150cb0d33c4e8bb0313fe99d11751f",
            "value": 485
          }
        },
        "a21642adbb644231a52d88d1f48c4c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfcbd5ae16cc41d1b5a4bb4061b8600f",
            "placeholder": "​",
            "style": "IPY_MODEL_e80379d7df924bf293152e02e1a43d94",
            "value": " 485/485 [00:00&lt;00:00, 5697.82 examples/s]"
          }
        },
        "b0a74e7ce090458cbab71ef948dcf516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3422b63c24194145a95b31e1151bafd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "608daa49e3194040ab34d876305c39c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56b77a010aa441059705a26548b9f735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc150cb0d33c4e8bb0313fe99d11751f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfcbd5ae16cc41d1b5a4bb4061b8600f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e80379d7df924bf293152e02e1a43d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "864fad3acc0b4dc6bba100b6d8155561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00ae29aa1a294eeebbd5e8d796882034",
              "IPY_MODEL_641a7caf02764f2b9254832d9a76fe28",
              "IPY_MODEL_d75ad51f03a84bada55520941bd8658e"
            ],
            "layout": "IPY_MODEL_0a1e89f90d494082b6dee8575b30787a"
          }
        },
        "00ae29aa1a294eeebbd5e8d796882034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c3bcee0711a40f8b4ea59792ffb933c",
            "placeholder": "​",
            "style": "IPY_MODEL_762175da54034f5ba1e6db902224179c",
            "value": "Map: 100%"
          }
        },
        "641a7caf02764f2b9254832d9a76fe28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18354cd9ec5a4108b1285c742194edaf",
            "max": 19823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1303c41e3f1448ee960fcc89b969c026",
            "value": 19823
          }
        },
        "d75ad51f03a84bada55520941bd8658e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5654fc2dc8b24a4197f0d584c9de2a80",
            "placeholder": "​",
            "style": "IPY_MODEL_2b2f5ba8dbe54b90a9b17cf4e3eb277c",
            "value": " 19823/19823 [00:01&lt;00:00, 19544.86 examples/s]"
          }
        },
        "0a1e89f90d494082b6dee8575b30787a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3bcee0711a40f8b4ea59792ffb933c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "762175da54034f5ba1e6db902224179c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18354cd9ec5a4108b1285c742194edaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1303c41e3f1448ee960fcc89b969c026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5654fc2dc8b24a4197f0d584c9de2a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b2f5ba8dbe54b90a9b17cf4e3eb277c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e2a844982d24acba9133e8b0626741a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf4666691f9c4456815b58aea1d02745",
              "IPY_MODEL_f14abf81dd3e4b9daedc236f24d7eca4",
              "IPY_MODEL_1038cf90b0e3457598e89210fe8dd915"
            ],
            "layout": "IPY_MODEL_65ab90aac2e3436d8377c814a731fd98"
          }
        },
        "cf4666691f9c4456815b58aea1d02745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64474a89459845a98842fa6f6b62dabc",
            "placeholder": "​",
            "style": "IPY_MODEL_c78c5a6e0d2e46379782237a36fbf6ab",
            "value": "Downloading builder script: 100%"
          }
        },
        "f14abf81dd3e4b9daedc236f24d7eca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ee504ae74ad4aaab5897c191aa87f2b",
            "max": 5937,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d33f4ff58e004d38b4b4698191689a5e",
            "value": 5937
          }
        },
        "1038cf90b0e3457598e89210fe8dd915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c062787b96154ef5bbba8773916eaa1c",
            "placeholder": "​",
            "style": "IPY_MODEL_bdc22413dd184900a16e0f57a4abb29b",
            "value": " 5.94k/5.94k [00:00&lt;00:00, 400kB/s]"
          }
        },
        "65ab90aac2e3436d8377c814a731fd98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64474a89459845a98842fa6f6b62dabc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c78c5a6e0d2e46379782237a36fbf6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ee504ae74ad4aaab5897c191aa87f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d33f4ff58e004d38b4b4698191689a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c062787b96154ef5bbba8773916eaa1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc22413dd184900a16e0f57a4abb29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3faffea176ec43dd924de5fcea9ca50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_294e8bf5f9bd4b0d9cbbb73791136f4a",
              "IPY_MODEL_2a7000af4d134f04abdd3bd83a74417e",
              "IPY_MODEL_dfcbe03b4ed84bf7a407b15d85adb062"
            ],
            "layout": "IPY_MODEL_f975748df3324290ad5d740b8c0df995"
          }
        },
        "294e8bf5f9bd4b0d9cbbb73791136f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cab5efdcfd24491bfe832447dd552d8",
            "placeholder": "​",
            "style": "IPY_MODEL_e3de1dd318924bdc9a2891e7fdfbdafa",
            "value": "Downloading extra modules: "
          }
        },
        "2a7000af4d134f04abdd3bd83a74417e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70a60570929942999c4dee9aa68785ae",
            "max": 1554,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a70dbf69991403f9c75ea9daba4bc24",
            "value": 1554
          }
        },
        "dfcbe03b4ed84bf7a407b15d85adb062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_937c964e8b6f40aeb91528ac81e7a03f",
            "placeholder": "​",
            "style": "IPY_MODEL_a368d291083049daba6b852744e2c80e",
            "value": " 4.07k/? [00:00&lt;00:00, 324kB/s]"
          }
        },
        "f975748df3324290ad5d740b8c0df995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cab5efdcfd24491bfe832447dd552d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3de1dd318924bdc9a2891e7fdfbdafa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70a60570929942999c4dee9aa68785ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a70dbf69991403f9c75ea9daba4bc24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "937c964e8b6f40aeb91528ac81e7a03f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a368d291083049daba6b852744e2c80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "093fe51d09d7405da2e4e38ee1cef1c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92f5ee6db4244390a1efef291c7a90da",
              "IPY_MODEL_6b204f18047d4507b613675e2ccd5d34",
              "IPY_MODEL_5816112834fc4d91a409913875f702de"
            ],
            "layout": "IPY_MODEL_6925a0a05c6941148095838a72fe5684"
          }
        },
        "92f5ee6db4244390a1efef291c7a90da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9183d317cc0b474ea5c593c27f4115f0",
            "placeholder": "​",
            "style": "IPY_MODEL_a6357d58d0544c75b88d8acba405ccec",
            "value": "Downloading extra modules: 100%"
          }
        },
        "6b204f18047d4507b613675e2ccd5d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faff76ad68694464bf739b95c54ea1b8",
            "max": 3344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91782e4e1a9b416ca27f2b2e1e81a23f",
            "value": 3344
          }
        },
        "5816112834fc4d91a409913875f702de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48d869e2882946119d35a225903939bd",
            "placeholder": "​",
            "style": "IPY_MODEL_3707032fc3814fd3b0411ae64beb19e3",
            "value": " 3.34k/3.34k [00:00&lt;00:00, 283kB/s]"
          }
        },
        "6925a0a05c6941148095838a72fe5684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9183d317cc0b474ea5c593c27f4115f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6357d58d0544c75b88d8acba405ccec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faff76ad68694464bf739b95c54ea1b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91782e4e1a9b416ca27f2b2e1e81a23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48d869e2882946119d35a225903939bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3707032fc3814fd3b0411ae64beb19e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d185131c8277440e8b35050624825fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cdf536350a84d37982662acb5c0f1d8",
              "IPY_MODEL_af3c93c08b0643e485e05237c421c4c6",
              "IPY_MODEL_01cc6ed716a74a4caf662849372a5620"
            ],
            "layout": "IPY_MODEL_1a0d6c07bcaa449aa654d7114ce497dd"
          }
        },
        "9cdf536350a84d37982662acb5c0f1d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ac934765648403cb9472d8e1ad43faf",
            "placeholder": "​",
            "style": "IPY_MODEL_b5d7248daeaf4b9cab4b1cb142b29f33",
            "value": "config.json: 100%"
          }
        },
        "af3c93c08b0643e485e05237c421c4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e14faacd3c4afab2dcf6c8f95a21cd",
            "max": 724,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b0c76dc11ae447daab8d5bee1410ad6",
            "value": 724
          }
        },
        "01cc6ed716a74a4caf662849372a5620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_416712d47459409b930dfcdf2ef01fc4",
            "placeholder": "​",
            "style": "IPY_MODEL_c7c698ba602d41f9b07511659e61b7f1",
            "value": " 724/724 [00:00&lt;00:00, 57.5kB/s]"
          }
        },
        "1a0d6c07bcaa449aa654d7114ce497dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac934765648403cb9472d8e1ad43faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5d7248daeaf4b9cab4b1cb142b29f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62e14faacd3c4afab2dcf6c8f95a21cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b0c76dc11ae447daab8d5bee1410ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "416712d47459409b930dfcdf2ef01fc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7c698ba602d41f9b07511659e61b7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "882efce3ae2c4533b926ad4f6f050a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_398fce1612ba472ba87b5b01925ac463",
              "IPY_MODEL_f290e6cb924f43c992fa576ca2c72871",
              "IPY_MODEL_5f832b6880df4ea3b930e968f08b0a95"
            ],
            "layout": "IPY_MODEL_031fc22ac76e4e5f93c80c758b505fc1"
          }
        },
        "398fce1612ba472ba87b5b01925ac463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8665a0c04627452aabc7dcbaacaa7839",
            "placeholder": "​",
            "style": "IPY_MODEL_e6270435d043495eb2339e7b35d5e3cc",
            "value": "model.safetensors: 100%"
          }
        },
        "f290e6cb924f43c992fa576ca2c72871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_732bcb5e832e4de7a689a75ec066b57e",
            "max": 538090408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c350ddc315a84c64941ff745e445f1ce",
            "value": 538090408
          }
        },
        "5f832b6880df4ea3b930e968f08b0a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e2343192dd244c29f834a28c0319ef7",
            "placeholder": "​",
            "style": "IPY_MODEL_037ff0fdcbe748db8d3ef7ff22a0f603",
            "value": " 538M/538M [00:02&lt;00:00, 263MB/s]"
          }
        },
        "031fc22ac76e4e5f93c80c758b505fc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8665a0c04627452aabc7dcbaacaa7839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6270435d043495eb2339e7b35d5e3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "732bcb5e832e4de7a689a75ec066b57e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c350ddc315a84c64941ff745e445f1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e2343192dd244c29f834a28c0319ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "037ff0fdcbe748db8d3ef7ff22a0f603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4af22e8b1eb4937989f945658cfe48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4932d0d66464bcf806a099c5cf62280",
              "IPY_MODEL_a87bef85e9c54e1aa6c59d8386584560",
              "IPY_MODEL_596257831ae640598164ae65ece19e48"
            ],
            "layout": "IPY_MODEL_a5b820493fed481583525e458f0c51a3"
          }
        },
        "f4932d0d66464bcf806a099c5cf62280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa653f48e63343fc9aef558dc3677e3c",
            "placeholder": "​",
            "style": "IPY_MODEL_c96634a573b44c8d87460e44783a400c",
            "value": "generation_config.json: 100%"
          }
        },
        "a87bef85e9c54e1aa6c59d8386584560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59e48ebffc3c4f69a893c020c12246d2",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d28a4a1ecae41f9a0d2c78a5fd3eb55",
            "value": 111
          }
        },
        "596257831ae640598164ae65ece19e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed541c68bdfa41cf8a3b6ba70f33891b",
            "placeholder": "​",
            "style": "IPY_MODEL_5f3708aa83954bafb199f1f8e3606eba",
            "value": " 111/111 [00:00&lt;00:00, 9.03kB/s]"
          }
        },
        "a5b820493fed481583525e458f0c51a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa653f48e63343fc9aef558dc3677e3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c96634a573b44c8d87460e44783a400c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59e48ebffc3c4f69a893c020c12246d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d28a4a1ecae41f9a0d2c78a5fd3eb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed541c68bdfa41cf8a3b6ba70f33891b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f3708aa83954bafb199f1f8e3606eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18daca22c45f4fe98849abb676e87c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fae0bb6d7feb45d18652036c56397a6b",
              "IPY_MODEL_8546b06246da42fc9232d54d143d89a0",
              "IPY_MODEL_2c714db491a94069bf4dd9d280faa33f"
            ],
            "layout": "IPY_MODEL_5178603cb8ee4975ad7a7b77f7eaf283"
          }
        },
        "fae0bb6d7feb45d18652036c56397a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ac669f5c06c40a7a7037190f18697b1",
            "placeholder": "​",
            "style": "IPY_MODEL_07a8c3baa6c64858b663d0e55fa3baf0",
            "value": "Tokenizing train dataset: 100%"
          }
        },
        "8546b06246da42fc9232d54d143d89a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3839c37d810349a1acb59a58818d3018",
            "max": 25600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3752c3b189d408b8923b4e972b43d51",
            "value": 25600
          }
        },
        "2c714db491a94069bf4dd9d280faa33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_929e4aff94f643d696a66d39dfa77094",
            "placeholder": "​",
            "style": "IPY_MODEL_5543b9e5555e49459d70da02502373b6",
            "value": " 25600/25600 [00:25&lt;00:00, 1047.97 examples/s]"
          }
        },
        "5178603cb8ee4975ad7a7b77f7eaf283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ac669f5c06c40a7a7037190f18697b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07a8c3baa6c64858b663d0e55fa3baf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3839c37d810349a1acb59a58818d3018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3752c3b189d408b8923b4e972b43d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "929e4aff94f643d696a66d39dfa77094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5543b9e5555e49459d70da02502373b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cde311e0d6948d197d4bdd37075a4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43c6da6c35314052a91cb576e3e4f9fb",
              "IPY_MODEL_1af329647f13494a993295bb6645c3d5",
              "IPY_MODEL_8feca2090ed641f68371d93ea56345aa"
            ],
            "layout": "IPY_MODEL_9d5c47a69c4c40d9afb1ddbc5f86a760"
          }
        },
        "43c6da6c35314052a91cb576e3e4f9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32bd8246889e4dc0981a491c9ab94c71",
            "placeholder": "​",
            "style": "IPY_MODEL_a535c3521fb4430bbe700785ff8cef53",
            "value": "Tokenizing train dataset: 100%"
          }
        },
        "1af329647f13494a993295bb6645c3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5465687ec934ea49184c18c7a2602f7",
            "max": 25600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db835d03d55e4cd5becbd47f92ecdb5e",
            "value": 25600
          }
        },
        "8feca2090ed641f68371d93ea56345aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_682a48aefd1443d297c4a989f111cd7b",
            "placeholder": "​",
            "style": "IPY_MODEL_a5292e3ad34b4564a2aa3d1fce5e9c00",
            "value": " 25600/25600 [00:27&lt;00:00, 935.50 examples/s]"
          }
        },
        "9d5c47a69c4c40d9afb1ddbc5f86a760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32bd8246889e4dc0981a491c9ab94c71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a535c3521fb4430bbe700785ff8cef53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5465687ec934ea49184c18c7a2602f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db835d03d55e4cd5becbd47f92ecdb5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "682a48aefd1443d297c4a989f111cd7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5292e3ad34b4564a2aa3d1fce5e9c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yingjia-Wan/C4AIScholarsChallenge2024/blob/main/Yingjia_Wan_C4AIScholarsChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Notes from Applicant:**\n",
        "\n",
        "Inside some subsections of each part, I wrote short reports in [text blocks] to answer some task questions in more detail. :)"
      ],
      "metadata": {
        "id": "R0CEB1tBqUXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Background**\n",
        "\n",
        "Welcome to the C4AI Scholars Program Take-Home Challenge! This exercise is designed to allow you to showcase your engineering and problem solving skills. The Challenge consists of different challenges including:\n",
        "\n",
        "*   Identifying bugs, and getting the code working. This is designed to test your ability to grapple with real world engineering challenges.\n",
        "*   Testing your ability to generate code for a specified problem.\n",
        "*   An opportunity for you to attempt an optional challenge question that extends the original problem set.\n",
        "\n",
        "These tasks were chosen as a setting to see how you think about problems, even if they are not in your own research field of interest. The tasks and dataset are not meant to be indicative of the research goals of the Scholar Program. We purposefully have selected a simple toy problem so the focus is on how you think, and does not require significant machine learning resources (can be run in this colab).\n",
        "\n",
        "Good luck!\n",
        "\n",
        "**How to Use and Submit this Document?**\n",
        "\n",
        "*   **Make a copy of this document** and rename it **Firstname_Lastname_C4AIScholarsChallenge**\n",
        "*   Once you have completed all tasks, save and pin your revisions\n",
        "*   Submit the assignment by responding directly to this email with a link to your final document by Sunday, September 15th, 11 PM PDT."
      ],
      "metadata": {
        "id": "Ygcggh-VPClr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tjokNL8DVD2"
      },
      "source": [
        "## **Coding Challenge Part 1: Debugging custom SmolLM code [10 points]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6or_dbUDVD3"
      },
      "source": [
        "In this coding challenge, you are required to debug and fix a bare-bones implementation of the following model.\n",
        "\n",
        "**Model** : SmolLM-135M can be found at [HuggingFace](https://huggingface.co/HuggingFaceTB/SmolLM-135M).\n",
        "\n",
        "We have 10 bugs in the following implementation.\n",
        "There is a `check_solution` function for your convenience to verify you have correctly identified all the bugs. If you have found all bugs, the generated outputs will match the reference model exactly.\n",
        "\n",
        "**Rules**:\n",
        "1. **Bug Definition:**\n",
        "  - There are 10 bugs to be fixed.\n",
        "  - A bug is *defined as **{incorrect, missing, unnecessary}** lines of code*.\n",
        "  - You earn 1 point for each correctly identified and fixed bug.\n",
        "2. **Fix Guidelines:**\n",
        "  - You are encouraged to make the smallest possible fix, wherever possible (e.g. edit a line instead of replacing it entirely).\n",
        "  - Do not optimize the code; only fix the bugs. The implementation is *intentionally* non-optimized but valid.\n",
        "3. **Documentation:** Document each fix by adding a comment on the line above the fix: : `### BUG FIX ###`.\n",
        "4. **Sections:** *1. Setup [Helper Functions]* and *3. Test* don't contain bugs and shouldn't be changed.\n",
        "5. **Submission:** Your final submission should be the exact same file except with your proposed fixes and the respective comments as per Rule #3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67d4055d-bb2d-49c7-a7e1-7f53fdb49658"
      },
      "source": [
        "## 1. Setup [Helper Functions]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################################################################\n",
        "############################################## DO NOT CHANGE[START] ##################################################\n",
        "######################################################################################################################\n",
        "\n",
        "\n",
        "# [Don't use. Rate limit issues.] Use gdown to get weights file(BareBones_SmolLM-135M.pt) at https://drive.google.com/file/d/1tY46FSJEhGYRrfKRQTjJ1Cc7q9psaKUU/view . gdown should be installed by default else use `pip install gdown`\n",
        "# !gdown 1tY46FSJEhGYRrfKRQTjJ1Cc7q9psaKUU\n",
        "\n",
        "\n",
        "# [Recommended]Use HF to download the weights\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/dsouzadaniel/C4AI_SMOLLM135\n",
        "!mv C4AI_SMOLLM135/BareBones_SmolLM-135M.pt ./\n",
        "!ls"
      ],
      "metadata": {
        "id": "EIVmK-EX9KJa",
        "outputId": "64bd566e-1fed-4bd0-a07f-63004d17c0c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'C4AI_SMOLLM135'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (6/6), 2.11 KiB | 2.11 MiB/s, done.\n",
            "BareBones_SmolLM-135M.pt  C4AI_SMOLLM135  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d108504-1504-4ca7-a5ae-55975798b699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "d185131c8277440e8b35050624825fb3",
            "9cdf536350a84d37982662acb5c0f1d8",
            "af3c93c08b0643e485e05237c421c4c6",
            "01cc6ed716a74a4caf662849372a5620",
            "1a0d6c07bcaa449aa654d7114ce497dd",
            "7ac934765648403cb9472d8e1ad43faf",
            "b5d7248daeaf4b9cab4b1cb142b29f33",
            "62e14faacd3c4afab2dcf6c8f95a21cd",
            "6b0c76dc11ae447daab8d5bee1410ad6",
            "416712d47459409b930dfcdf2ef01fc4",
            "c7c698ba602d41f9b07511659e61b7f1",
            "882efce3ae2c4533b926ad4f6f050a67",
            "398fce1612ba472ba87b5b01925ac463",
            "f290e6cb924f43c992fa576ca2c72871",
            "5f832b6880df4ea3b930e968f08b0a95",
            "031fc22ac76e4e5f93c80c758b505fc1",
            "8665a0c04627452aabc7dcbaacaa7839",
            "e6270435d043495eb2339e7b35d5e3cc",
            "732bcb5e832e4de7a689a75ec066b57e",
            "c350ddc315a84c64941ff745e445f1ce",
            "6e2343192dd244c29f834a28c0319ef7",
            "037ff0fdcbe748db8d3ef7ff22a0f603",
            "f4af22e8b1eb4937989f945658cfe48b",
            "f4932d0d66464bcf806a099c5cf62280",
            "a87bef85e9c54e1aa6c59d8386584560",
            "596257831ae640598164ae65ece19e48",
            "a5b820493fed481583525e458f0c51a3",
            "fa653f48e63343fc9aef558dc3677e3c",
            "c96634a573b44c8d87460e44783a400c",
            "59e48ebffc3c4f69a893c020c12246d2",
            "9d28a4a1ecae41f9a0d2c78a5fd3eb55",
            "ed541c68bdfa41cf8a3b6ba70f33891b",
            "5f3708aa83954bafb199f1f8e3606eba"
          ]
        },
        "outputId": "07922d97-ad52-44e7-e196-13ad5b2773b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/724 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d185131c8277440e8b35050624825fb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/538M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "882efce3ae2c4533b926ad4f6f050a67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4af22e8b1eb4937989f945658cfe48b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Libraries\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import math\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Model initialization/settings\n",
        "checkpoint=\"HuggingFaceTB/SmolLM-135M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "__reference_model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
        "__reference_model.eval()\n",
        "\n",
        "class smolConfig:\n",
        "    vocab_size=49152\n",
        "    hidden_size=576\n",
        "    intermediate_size=1536\n",
        "    num_hidden_layers = 30\n",
        "    num_heads = 9\n",
        "    kv_heads=3\n",
        "config = smolConfig\n",
        "\n",
        "# Helper Functions\n",
        "def __generate(model, inputs, num_tokens):\n",
        "    collect = []\n",
        "    for _ in range(num_tokens):\n",
        "        output = model(**inputs)\n",
        "        output_id = torch.argmax(output['logits'][0,-1]).item()\n",
        "        collect.append(output_id)\n",
        "        if output_id==tokenizer.eos_token_id:\n",
        "            break\n",
        "        inputs['input_ids'] = torch.unsqueeze(torch.cat([inputs['input_ids'][0],torch.tensor([output_id])]),dim=0)\n",
        "        inputs['attention_mask'] = torch.ones_like(inputs['input_ids'])\n",
        "    return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(collect))\n",
        "\n",
        "def check_solution(prompt, num_tokens, model_A, model_B):\n",
        "    print()\n",
        "    print(f\"{'>'*20}\\n\\tPrompt\\n{'<'*20}\\n{prompt}\\n\\n\")\n",
        "    model_inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    print(f\"{'>'*30}\\n\\tModel_A Generation\\n{'<'*30}\\n{__generate(model_A,  model_inputs, num_tokens)}\")\n",
        "    print(\"\\n\\n\")\n",
        "    model_inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    print(f\"{'>'*30}\\n\\tModel_B Generation\\n{'<'*30}\\n{__generate(model_B,  model_inputs, num_tokens)}\")\n",
        "\n",
        "######################################################################################################################\n",
        "############################################### DO NOT CHANGE[END] ###################################################\n",
        "######################################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62103e4d-e1b3-4687-a30a-65842ae1b8a9"
      },
      "source": [
        "## 2. Custom SmolLM (for BugFixes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ccfc40a-5fee-4f9a-81f3-8339a69ad5cf"
      },
      "outputs": [],
      "source": [
        "def rotate_half(x):\n",
        "    x1 = x[..., : x.shape[-1] // 2]\n",
        "    x2 = x[..., x.shape[-1] // 2 :]\n",
        "    return torch.cat((-x2, x1), dim=-1)\n",
        "\n",
        "def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
        "    cos = cos.unsqueeze(unsqueeze_dim)\n",
        "    sin = sin.unsqueeze(unsqueeze_dim)\n",
        "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
        "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
        "    return q_embed, k_embed\n",
        "\n",
        "def repeat_kv(hidden_states, n_rep):\n",
        "    batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
        "\n",
        "    ### BUG FIX ###  [missing]\n",
        "    if n_rep == 1: # if n_rep=1, no need to reshape hidden_states\n",
        "        return hidden_states\n",
        "\n",
        "    hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
        "    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
        "\n",
        "class RotaryEmbedder(nn.Module):\n",
        "    def __init__(self, dim, base):\n",
        "        super().__init__()\n",
        "        self.freq = 1/(base ** (torch.arange(0, dim, 2, dtype=torch.int64).float()/dim))\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(self,x):\n",
        "        pos = torch.arange(x.shape[-2],dtype=torch.long)\n",
        "        angles = torch.einsum('f,p->fp', self.freq, pos.float()).unsqueeze(dim=0)\n",
        "\n",
        "        ### BUG FIX ### [incorrect]\n",
        "        # emb = torch.cat((angles, angles), dim=-1)\n",
        "        emb = torch.cat((angles, angles), dim=-2)\n",
        "\n",
        "        ### BUG FIX ### [missing]\n",
        "        emb = emb.permute(0, 2, 1)\n",
        "\n",
        "        return emb.cos(), emb.sin()\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, hidden_size, intermediate_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.intermediate_size = intermediate_size\n",
        "        self.W_gate = nn.Linear(self.hidden_size, self.intermediate_size, bias=False)\n",
        "        self.W_up = nn.Linear(self.hidden_size, self.intermediate_size, bias=False)\n",
        "        self.W_down = nn.Linear(self.intermediate_size, self.hidden_size, bias=False)\n",
        "        self.act_fn = torch.nn.modules.activation.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        down_proj = self.W_down(self.act_fn((self.W_gate(x)) * self.W_up(x)))\n",
        "        return down_proj\n",
        "\n",
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, hidden_size, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "        self.variance_epsilon = eps\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
        "        ### BUG FIX ### [incorrect] it should divide by standard deviation using rsqrt.\n",
        "        hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
        "        # hidden_states = hidden_states * torch.sqrt(variance + self.variance_epsilon) [original]\n",
        "\n",
        "        return self.weight * hidden_states\n",
        "\n",
        "\n",
        "class RopeAttention(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.hidden_size=config.hidden_size\n",
        "        self.num_heads = config.num_heads\n",
        "        self.head_dim = config.hidden_size//self.num_heads\n",
        "        self.kv_heads = config.kv_heads\n",
        "        self.rope_theta = 10000.0\n",
        "\n",
        "        self.W_query = nn.Linear(config.hidden_size, self.num_heads * self.head_dim, bias=False)\n",
        "        self.W_key = nn.Linear(config.hidden_size, self.kv_heads * self.head_dim, bias=False)\n",
        "        self.W_value = nn.Linear(config.hidden_size, self.kv_heads * self.head_dim, bias=False)\n",
        "        self.W_output = nn.Linear(config.hidden_size, config.hidden_size, bias=False)\n",
        "        self.rotary_emb = RotaryEmbedder(base=self.rope_theta,\n",
        "                                         dim=config.hidden_size//self.num_heads)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask= None,\n",
        "    ):\n",
        "        b, q, _ = hidden_states.size()\n",
        "\n",
        "        q_states = self.W_query(hidden_states)\n",
        "        k_states = self.W_key(hidden_states)\n",
        "        v_states = self.W_value(hidden_states)\n",
        "\n",
        "        q_states = q_states.view(b, q, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        k_states = k_states.view(b, q, self.kv_heads, self.head_dim).transpose(1, 2)\n",
        "        v_states = v_states.view(b, q, self.kv_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        cos, sin = self.rotary_emb(v_states)\n",
        "        q_states, k_states = apply_rotary_pos_emb(q_states, k_states, cos, sin)\n",
        "\n",
        "        ### BUG FIX ### [incorrect] __kv_groups must be a int not a float\n",
        "        __kv_groups = self.num_heads // self.kv_heads\n",
        "        # __kv_groups = self.num_heads / self.kv_heads # [original]\n",
        "\n",
        "        k_states = repeat_kv(k_states, __kv_groups)\n",
        "        v_states = repeat_kv(v_states, __kv_groups)\n",
        "\n",
        "        attn_weights = torch.matmul(q_states, k_states.transpose(2, 3)) / math.sqrt(self.hidden_size)\n",
        "\n",
        "\n",
        "        ### BUG FIX ### [incorrect] add if condition\n",
        "        if attention_mask is not None:\n",
        "            attn_weights = attn_weights + attention_mask\n",
        "        # attn_weights = attn_weights + attention_mask #[original]\n",
        "\n",
        "        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n",
        "        ### BUG FIX ### [incorrect] specify dropout p\n",
        "        attn_weights = nn.functional.dropout(attn_weights, p=0.1)\n",
        "        # attn_weights = nn.functional.dropout(attn_weights)\n",
        "\n",
        "        attn_output = torch.matmul(attn_weights, v_states)\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous()\n",
        "        attn_output = attn_output.reshape(b, q, -1)\n",
        "\n",
        "        return attn_output\n",
        "\n",
        "class LlamaDecoder(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.self_attn = RopeAttention(config)\n",
        "        self.mlp = MLP(hidden_size=config.hidden_size, intermediate_size=config.intermediate_size)\n",
        "        self.pre_attn_rmsnorm = RMSNorm(config.hidden_size, eps=1e-05)\n",
        "        self.pre_mlp_rmsnorm = RMSNorm(config.hidden_size, eps=1e-05)\n",
        "\n",
        "    def forward(self,hidden_states, attention_mask):\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.pre_attn_rmsnorm(hidden_states)\n",
        "        ### BUG FIX ### [incorrect]\n",
        "        attention_mask = torch.triu(torch.full((hidden_states.shape[1], hidden_states.shape[1]), fill_value=float('-inf')), diagonal=1)\n",
        "        # attention_mask = torch.triu(torch.full((attention_mask.shape[-1],attention_mask.shape[-1]), fill_value=float('-inf')),diagonal=1) [original]\n",
        "\n",
        "        hidden_states = self.self_attn(\n",
        "            hidden_states=hidden_states,\n",
        "            attention_mask=attention_mask,\n",
        "        )\n",
        "        hidden_states += residual\n",
        "\n",
        "        ### BUG FIX ### [missing]\n",
        "        residual = hidden_states # update the residual for the next blck\n",
        "\n",
        "        hidden_states = self.pre_mlp_rmsnorm(hidden_states)\n",
        "        hidden_states = self.mlp(hidden_states)\n",
        "        hidden_states += residual\n",
        "\n",
        "        outputs = (hidden_states,)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class smolModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.embed_tokens = nn.Embedding(num_embeddings=config.vocab_size,\n",
        "                                         embedding_dim=config.hidden_size)\n",
        "        self.layers = nn.ModuleList([LlamaDecoder(config) for _ in range(config.num_hidden_layers)])\n",
        "        self.norm = RMSNorm(config.hidden_size, eps=1e-05)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids= None,\n",
        "        attention_mask= None,\n",
        "    ):\n",
        "        inputs_embeds = self.embed_tokens(input_ids)\n",
        "        hidden_states = inputs_embeds\n",
        "        for decoder_layer in self.layers:\n",
        "            layer_outputs = decoder_layer(\n",
        "                hidden_states,\n",
        "                attention_mask=attention_mask,\n",
        "            )\n",
        "            hidden_states = layer_outputs[0]\n",
        "        hidden_states = self.norm(hidden_states)\n",
        "        return [hidden_states]\n",
        "\n",
        "\n",
        "class smolLM(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.model = smolModel(config)\n",
        "        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
        "\n",
        "    def forward(self,input_ids,attention_mask):\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "        )\n",
        "        ### BUG FIX ### [incorrect] remove squeeze()\n",
        "        hidden_states = outputs[0]\n",
        "        # hidden_states = outputs[0].squeeze() #[original]\n",
        "\n",
        "        logits = self.lm_head(hidden_states)\n",
        "        logits = logits.float()\n",
        "        return {'logits':logits}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "__test_model = smolLM(config)\n",
        "__test_model.load_state_dict(torch.load('BareBones_SmolLM-135M.pt'), strict=False)\n",
        "__test_model.eval()"
      ],
      "metadata": {
        "id": "jPRkWRMLlGmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7872f37-eadd-4543-af51-97da68db868e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-9e98cf1d0caa>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  __test_model.load_state_dict(torch.load('BareBones_SmolLM-135M.pt'), strict=False)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "smolLM(\n",
              "  (model): smolModel(\n",
              "    (embed_tokens): Embedding(49152, 576)\n",
              "    (layers): ModuleList(\n",
              "      (0-29): 30 x LlamaDecoder(\n",
              "        (self_attn): RopeAttention(\n",
              "          (W_query): Linear(in_features=576, out_features=576, bias=False)\n",
              "          (W_key): Linear(in_features=576, out_features=192, bias=False)\n",
              "          (W_value): Linear(in_features=576, out_features=192, bias=False)\n",
              "          (W_output): Linear(in_features=576, out_features=576, bias=False)\n",
              "          (rotary_emb): RotaryEmbedder()\n",
              "        )\n",
              "        (mlp): MLP(\n",
              "          (W_gate): Linear(in_features=576, out_features=1536, bias=False)\n",
              "          (W_up): Linear(in_features=576, out_features=1536, bias=False)\n",
              "          (W_down): Linear(in_features=1536, out_features=576, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (pre_attn_rmsnorm): RMSNorm()\n",
              "        (pre_mlp_rmsnorm): RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8d4fc28-1962-4f42-9378-22a683f4978d"
      },
      "source": [
        "# 3. Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df559177-e725-41f6-8369-50e460165f78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e82cdb1-6e99-49dd-916c-ae2e5571f106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>>>>>>>>>>>>>>\n",
            "\tPrompt\n",
            "<<<<<<<<<<<<<<<<<<<<\n",
            "Given the following film movie by a critic, rate it out of 10. Respond in a single number.\n",
            "\n",
            "The movie started off extremely well, but just got worse after that.\n",
            "The storyline was all over the place and everyone acted terribly.\n",
            " 10/10 would not recommend! \n",
            "\n",
            " \n",
            "\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "\tModel_A Generation\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "\tModel_B Generation\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            " wrongs\n"
          ]
        }
      ],
      "source": [
        "######################################################################################################################\n",
        "############################################## DO NOT CHANGE[START] ##################################################\n",
        "######################################################################################################################\n",
        "\n",
        "###### TESTING PROMPTS\n",
        "# Single-Token Quick Test\n",
        "check_solution(prompt=\"Given the following film movie by a critic, rate it out of 10. Respond in a single number.\\n\\nThe movie started off extremely well, but just got worse after that.\\nThe storyline was all over the place and everyone acted terribly.\\n 10/10 would not recommend! \\n\\n \",\n",
        "               num_tokens=1,\n",
        "               model_A=__reference_model,\n",
        "               model_B=__test_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Token Quick Test\n",
        "check_solution(prompt=\"Where is the Nile located?\",\n",
        "               num_tokens=50,\n",
        "               model_A=__reference_model,\n",
        "               model_B=__test_model)\n",
        "\n",
        "######################################################################################################################\n",
        "############################################### DO NOT CHANGE[END] ###################################################\n",
        "######################################################################################################################"
      ],
      "metadata": {
        "id": "cQZd2U8naBGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8419d5-8188-4c94-b67e-27b160f842f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>>>>>>>>>>>>>>\n",
            "\tPrompt\n",
            "<<<<<<<<<<<<<<<<<<<<\n",
            "Where is the Nile located?\n",
            "\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "\tModel_A Generation\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "\n",
            "The Nile River is located in the Nile Delta in the Nile River Basin, which is a region of Africa. It is the longest river in the world, with a length of 4,330 miles (6,900 km\n",
            "\n",
            "\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "\tModel_B Generation\n",
            "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "pretationBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone exhibitionsligBone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Coding Challenge Part 2: Teach SmolLM to do grammatical error correction [15 points]**"
      ],
      "metadata": {
        "id": "-uBeG0ZQQC8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this part is to train the SmolLM-135M model to perform grammatical error correction (GEC) using the Grammarly CoEdIT dataset. This [dataset](https://huggingface.co/datasets/grammarly/coedit), derived from the [CoEdIT project](https://arxiv.org/abs/2305.09857), provides a rich collection of text editing instructions and examples. The task involves several key steps that mimic conventional alignment processes:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bSiBKZ9cU54t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.1 Supervised Fine-Tuning (SFT) on Training Data [5 points]**\n",
        "\n",
        "* Fine-tune the [SmolLM-135M model](https://huggingface.co/HuggingFaceTB/SmolLM-135M) using the CoEdIT dataset, which includes input sentences with grammatical errors and their corrected versions.\n",
        "* Use the training GEC portion of the CoEdIT dataset to teach the model how to correct grammatical errors effectively.\n",
        "* Calculate the BLEU score on the validation set to evaluate the model's performance in generating grammatically correct sentences. Ensure that this evaluation process is reusable for later comparisons.\n",
        "* Search for an optimal set of hyperparameters, such as the learning rate. We provide an estimated BLEU score that you should aim to achieve after one epoch. However, you may achieve a better score by finding the most suitable hyperparameters. **Do not train for more than 3 epochs -- we do not expect extensive training time.**\n",
        "* For Part 2, don't use additional libraries, if an imported library is missing, install it with **pip install**."
      ],
      "metadata": {
        "id": "CKCuZ-0Poi2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers trl torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Download the GEC data\n",
        "full_train_ds = load_dataset(\"grammarly/coedit\", split=\"train\")\n",
        "full_test_ds = load_dataset(\"grammarly/coedit\", split=\"validation\")"
      ],
      "metadata": {
        "id": "7PAq9wgdQDpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Filter examples, keeping only GEC task\n",
        "\n",
        "def filter_gec(example):\n",
        "    return example['task'] == 'gec'\n",
        "\n",
        "gec_train_ds = full_train_ds.filter(filter_gec)\n",
        "gec_val_ds = full_test_ds.filter(filter_gec)\n",
        "\n",
        "# adding the 'text' items to dataset to be compatible with SFTTrainer\n",
        "# (alternative is setting a formatter function: https://huggingface.co/docs/trl/en/sft_trainer#customize-your-prompts-using-packed-dataset)\n",
        "def add_text_field(example):\n",
        "    example['text'] = f\"{example['src']}. \\nAnswer: {example['tgt']}\\n\\n\"\n",
        "    example['prompt'] = f\"{example['src']}. \\nAnswer: \"\n",
        "    return example\n",
        "\n",
        "train_ds = gec_train_ds.map(add_text_field)\n",
        "val_ds = gec_val_ds.map(add_text_field)\n",
        "\n",
        "# Expected number of samples\n",
        "print(f\"Train dataset size: {len(train_ds)}\")\n",
        "print(f\"Validation dataset size: {len(val_ds)}\")"
      ],
      "metadata": {
        "id": "2G5Zjn_7wKcN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d230fb6-1a96-4959-ef10-7f76aee8fbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 19823\n",
            "Validation dataset size: 485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected number of train and test samples are 19823 and 485, respectively."
      ],
      "metadata": {
        "id": "RGDp47vndq9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"HuggingFaceTB/SmolLM-135M\"\n",
        "\n",
        "# TODO: Load the model and the tokenizer from huggingface\n",
        "\n",
        "# Check if a GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "D4KAJRaBhRnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5839e71-390b-496b-d591-bf887a20b0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRL - Transformer Reinforcement Learning -- https://huggingface.co/docs/trl/en/index\n",
        "from trl import SFTConfig, SFTTrainer\n",
        "\n",
        "# TODO: Run SFT\n",
        "\n",
        "# hyperparameters\n",
        "config = SFTConfig(\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=512,                 # max_seq_length set based on dataset length stats\n",
        "    per_device_train_batch_size=16,     # Batch size set for efficiency\n",
        "    learning_rate=1e-5,\n",
        "    num_train_epochs=3,\n",
        "    save_total_limit=1,\n",
        "    output_dir=\"/tmp/SFT\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model,\n",
        "    args=config,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_ds\n",
        ")\n",
        "\n",
        "# Train the model (takes apx. 5-10 min for 1 epoch on T4 GPU)\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "RMqSVczarkSN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482,
          "referenced_widgets": [
            "ffad28e7766648cca2ccb879ac15d6fc",
            "739ccf6e14f34468915df2644705df8f",
            "f3177c05ab8a45ca8fd5e4fa0b255760",
            "5fb87059d6444393baafbcd5409e883f",
            "4ebf349fe6944de2a9da0eb7d4c9b11a",
            "83bf34d731c44b3190f45138899140a8",
            "23c3cd696ad948108d298046f1a57228",
            "9003c3bf1ccf44fb869fc8eaeb0107fa",
            "5ad40792bbe44bacaf4af4c16ec35cb8",
            "2aa454a705154639a5f21f062d9dd35f",
            "5012179bc2044e1e8c51b560b914616b",
            "3b31badbfcf64cb0a63cbbe5d16190a1",
            "3e34a15ee516464288245fca71db2006",
            "7f3ea23a0c854ca689c1d4ce76eeab5c",
            "a21642adbb644231a52d88d1f48c4c98",
            "b0a74e7ce090458cbab71ef948dcf516",
            "3422b63c24194145a95b31e1151bafd1",
            "608daa49e3194040ab34d876305c39c1",
            "56b77a010aa441059705a26548b9f735",
            "bc150cb0d33c4e8bb0313fe99d11751f",
            "dfcbd5ae16cc41d1b5a4bb4061b8600f",
            "e80379d7df924bf293152e02e1a43d94",
            "864fad3acc0b4dc6bba100b6d8155561",
            "00ae29aa1a294eeebbd5e8d796882034",
            "641a7caf02764f2b9254832d9a76fe28",
            "d75ad51f03a84bada55520941bd8658e",
            "0a1e89f90d494082b6dee8575b30787a",
            "3c3bcee0711a40f8b4ea59792ffb933c",
            "762175da54034f5ba1e6db902224179c",
            "18354cd9ec5a4108b1285c742194edaf",
            "1303c41e3f1448ee960fcc89b969c026",
            "5654fc2dc8b24a4197f0d584c9de2a80",
            "2b2f5ba8dbe54b90a9b17cf4e3eb277c"
          ]
        },
        "outputId": "eadca111-05c0-415e-c75f-9d70d2c4c995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/19823 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffad28e7766648cca2ccb879ac15d6fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/485 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b31badbfcf64cb0a63cbbe5d16190a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/19823 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "864fad3acc0b4dc6bba100b6d8155561"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:407: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3717' max='3717' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3717/3717 09:06, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.782900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.620400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.565400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.550100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.529500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.519500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.509000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3717, training_loss=1.5781581694957292, metrics={'train_runtime': 548.3304, 'train_samples_per_second': 108.455, 'train_steps_per_second': 6.779, 'total_flos': 3669652263306240.0, 'train_loss': 1.5781581694957292, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report on Part 2.1\n",
        "\n",
        "#### + About hyperparameter search:\n",
        "\n",
        "The considered factors for searching for the optimal hyperparameters in general include: computational efficiency and performance (using BLEU score as the proxy). The model trained with the current hyperparameters achieves a BLEU evaluation score of 0.4107 (1 epoch) and 0.4546 (3 epoch).\n",
        "\n",
        "\n",
        "Here is a partial list of reference documents I considered:\n",
        "- SFTConfig args doc: https://huggingface.co/docs/trl/v0.10.1/en/sft_trainer#trl.SFTConfig\n",
        "- trainer args doc: https://huggingface.co/docs/trl/en/sft_trainer\n",
        "- Model hyperparameter blog: https://huggingface.co/blog/smollm#hyperparameters-choice\n",
        "\n",
        "\n",
        "Here is a breakdown of how I chose the hyperparameters below:\n",
        "\n",
        "- max_seq_length=512:\n",
        "\n",
        "    I collected the length statistics of train_ds and val_ds ('text' field). Shorter max_seq_length will reduce the amount of padding needed and speed up training, while a longer value will ensure most input texts are fully captured rather than truncated prematurely.\n",
        "    As shown below, there is quite a length discrepancy between train_ds and val_ds. Based on the trade-off in efficiecny, preserving the dataset content, and improving the model performance in evaluation, I chose 512.\n",
        "        Statistics for 'text' field in train_ds:\n",
        "            Maximum length: 1413\n",
        "            Average length: 248.60354134086668\n",
        "            Median length: 229.0\n",
        "            90th Percentile: 389.0\n",
        "        Statistics for 'text' field in val_ds:\n",
        "            Maximum length: 1944\n",
        "            Average length: 556.9030927835051\n",
        "            Median length: 538.0\n",
        "            90th Percentile: 974.0\n",
        "        Statistics for combined train_ds and val_ds:\n",
        "            Maximum length: 1944\n",
        "            Average length: 255.96641717549733\n",
        "            Median length: 231.0\n",
        "            90th Percentile: 401.0\n",
        "\n",
        "- Others:\n",
        "    \n",
        "    The set values for other hyperparameters (e.g., per_device_train_batch_size=16, learning_rate=1e-5) as well as the exclusion of unspecified hyperparameters are decided based on several rounds of 1-epoch trial runs within the limited time, with the consideration of both efficiency and performance.\n",
        "\n",
        "\n",
        "- (prompt template):\n",
        "\n",
        "    I found that prompt templates can have a significant impact on the training performance, which is possibly related to how the base model is pretrained and aligned. My current prompt template (in `add_text_field`) is what I found achieving the best performance with several rounds of 1-epoch trials.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3MGettWyJPa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE MODEL function\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "def save_trainer_checkpoint(trainer, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Save a checkpoint of the trained model for easy loading.\n",
        "    \"\"\"\n",
        "    # Create the directory if it doesn't exist\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        os.makedirs(checkpoint_path)\n",
        "\n",
        "    # Save the model and the trainer's state\n",
        "    trainer.save_model(checkpoint_path)  # Saves the model and tokenizer\n",
        "    # trainer.save_state()  # Saves the trainer's state including optimizer, scheduler, etc.\n",
        "\n",
        "    print(f\"Saved to {checkpoint_path}!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWmQJ2B-qac7",
        "outputId": "58aa65d5-d8ae-4c73-aafc-575a52d99ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the SFT_model:\n",
        "\n",
        "SFT_directory = '/content/drive/MyDrive/Application/C4AI/SFT_512_16_1e-5_epoch3_new'\n",
        "save_trainer_checkpoint(trainer, SFT_directory)"
      ],
      "metadata": {
        "id": "KN0bQyJx_mFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick test if your model works properly\n",
        "def format_text(text: str) -> str:\n",
        "    # here you may have formatting of the input that you adopted for training\n",
        "    return f\"{text}\\n ### Answer: \"\n",
        "\n",
        "# Example of how to run inference on a single example\n",
        "text = \"Fix grammatically: I likes turtles.\"\n",
        "# text = \"Make the sentence grammatical: I realized beyond this attitude would destroy me, and at this points my views of happiness shifted in a more realistic way, acknowledging happiness was step through steps process of overcoming challenge.\"\n",
        "inputs = tokenizer(format_text(text), return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
        "\n",
        "# Define the stop token (newline character)\n",
        "outputs = model.generate(**inputs, temperature=0.0, eos_token_id=tokenizer.eos_token_id,max_new_tokens=128)\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def extract_output(generated_text):\n",
        "    pred_start = generated_text.find('Answer: ') + len('Answer: ')\n",
        "    pred_end = generated_text.find('\\n\\n')\n",
        "    output = generated_text[pred_start:pred_end]\n",
        "    if 'Answer: ' in output:\n",
        "        output = output[output.find('Answer: ') + len('Answer: '):]\n",
        "    return output\n",
        "\n",
        "generated_text = extract_output(generated_text)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "RrwH3P8Q3hFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daef7d8d-77f5-4c2b-c473-d29f91cc28d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I like turtles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output: I like turtles."
      ],
      "metadata": {
        "id": "6Nat68x64Wlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "import evaluate\n",
        "\n",
        "# BLEU Score evaluation\n",
        "def evaluate_model(model, tokenizer, ds, output_file = \"/tmp/validation_output.json\", max_length=512, max_new_tokens=512):\n",
        "    preds = []\n",
        "    targets = []\n",
        "    batch_size=16 # evaluate in batches in parallel\n",
        "    srcs = []\n",
        "\n",
        "    for i in range(0, len(ds), batch_size):\n",
        "        batch = ds[i: i + batch_size]\n",
        "        input_texts = batch['prompt']\n",
        "        inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True, max_length=max_length).to(device)\n",
        "\n",
        "        generated_ids = model.generate(**inputs,\n",
        "                                       max_new_tokens=max_new_tokens,\n",
        "                                       eos_token_id=tokenizer.eos_token_id,\n",
        "                                       repetition_penalty=1.0) # curb generation length and repetition\n",
        "\n",
        "        for j in range(len(generated_ids)):\n",
        "            generated_text = tokenizer.decode(generated_ids[j], skip_special_tokens=True)\n",
        "            # extracted_output = generated_text[len(input_texts[j]):].strip()\n",
        "            extracted_output = extract_output(generated_text)\n",
        "            preds.append(extracted_output)\n",
        "            targets.append([batch['tgt'][j]])\n",
        "            srcs.append([batch['src'][j]])\n",
        "\n",
        "    bleu = evaluate.load(\"bleu\")\n",
        "    results = bleu.compute(predictions=preds, references=targets)\n",
        "\n",
        "    # Save predictions and references to a JSON file; useful for case study in pt3.\n",
        "    import json\n",
        "    validation_output = {\n",
        "        \"src\": srcs,\n",
        "        \"pred\": preds,\n",
        "        \"tgt\": targets,\n",
        "    }\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(validation_output, f, indent=4)\n",
        "\n",
        "\n",
        "    return results[\"bleu\"]"
      ],
      "metadata": {
        "id": "QTIrCDJOpUFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "cb2770ac-c6ee-48cc-a287-54d7c5f86f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Evaluate model, use the function given above\n",
        "\n",
        "bleu_score = evaluate_model(model, tokenizer, val_ds, output_file = \"/tmp/SFT_validation_output.json\", max_length=512, max_new_tokens=512)\n",
        "print(f\"BLEU score on validation set: {bleu_score}\")"
      ],
      "metadata": {
        "id": "m2d-nJpLqcaF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740,
          "referenced_widgets": [
            "2e2a844982d24acba9133e8b0626741a",
            "cf4666691f9c4456815b58aea1d02745",
            "f14abf81dd3e4b9daedc236f24d7eca4",
            "1038cf90b0e3457598e89210fe8dd915",
            "65ab90aac2e3436d8377c814a731fd98",
            "64474a89459845a98842fa6f6b62dabc",
            "c78c5a6e0d2e46379782237a36fbf6ab",
            "6ee504ae74ad4aaab5897c191aa87f2b",
            "d33f4ff58e004d38b4b4698191689a5e",
            "c062787b96154ef5bbba8773916eaa1c",
            "bdc22413dd184900a16e0f57a4abb29b",
            "3faffea176ec43dd924de5fcea9ca50b",
            "294e8bf5f9bd4b0d9cbbb73791136f4a",
            "2a7000af4d134f04abdd3bd83a74417e",
            "dfcbe03b4ed84bf7a407b15d85adb062",
            "f975748df3324290ad5d740b8c0df995",
            "9cab5efdcfd24491bfe832447dd552d8",
            "e3de1dd318924bdc9a2891e7fdfbdafa",
            "70a60570929942999c4dee9aa68785ae",
            "8a70dbf69991403f9c75ea9daba4bc24",
            "937c964e8b6f40aeb91528ac81e7a03f",
            "a368d291083049daba6b852744e2c80e",
            "093fe51d09d7405da2e4e38ee1cef1c4",
            "92f5ee6db4244390a1efef291c7a90da",
            "6b204f18047d4507b613675e2ccd5d34",
            "5816112834fc4d91a409913875f702de",
            "6925a0a05c6941148095838a72fe5684",
            "9183d317cc0b474ea5c593c27f4115f0",
            "a6357d58d0544c75b88d8acba405ccec",
            "faff76ad68694464bf739b95c54ea1b8",
            "91782e4e1a9b416ca27f2b2e1e81a23f",
            "48d869e2882946119d35a225903939bd",
            "3707032fc3814fd3b0411ae64beb19e3"
          ]
        },
        "outputId": "7c79ba25-cec4-4ba2-aa51-651fe2b96ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2888: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e2a844982d24acba9133e8b0626741a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3faffea176ec43dd924de5fcea9ca50b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "093fe51d09d7405da2e4e38ee1cef1c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score on validation set: 0.4545910286204956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected BLEU score after 1 epoch SFT is ~ 0.48."
      ],
      "metadata": {
        "id": "UGZ12G_TbweV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_and_read_samples(output_file=\"validation_output.json\", num_samples=10):\n",
        "    # Load the validation output file\n",
        "    with open(output_file, \"r\") as f:\n",
        "        validation_output = json.load(f)\n",
        "\n",
        "    # Extract predictions and references\n",
        "    predictions = validation_output[\"pred\"]\n",
        "    references = validation_output[\"tgt\"]\n",
        "    srcs = validation_output[\"src\"]\n",
        "\n",
        "    # Read the first num_samples samples\n",
        "    for i in range(num_samples):\n",
        "        print(f\"Sample {i + 1}:\")\n",
        "        print(f\"Source: {srcs[i]}\")\n",
        "        print(f\"Prediction: {predictions[i]}\")\n",
        "        print(f\"Reference: {references[i]}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "# Inspect SFT_model output\n",
        "load_and_read_samples(output_file=\"/tmp/SFT_validation_output.json\", num_samples=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjTGit63Gynj",
        "outputId": "a9057885-02b2-4477-cf8e-4f5de22ed30b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1:\n",
            "Source: ['Fix grammaticality: First of all, from you read just to found in the poems or novel what well-known critic have already found out, you looses the pleasures of reading something which is expecting to be a new experience to you.']\n",
            "Prediction:  First of all, from you, I read just to find out what well-known critic has already found out, you have lost the pleasures of reading something which is expecting to be a new experience to you.\n",
            "Reference: ['First of all, if you read just to find in the poem or novel what well-known critics have already found out, you lose the pleasure of reading something that is expected to be a new experience to you.']\n",
            "----------------------------------------\n",
            "Sample 2:\n",
            "Source: ['Fix grammatical errors: Their research shown that before Hurricane Sandy only \" about 50 percent during resident used the emergency departments, \" and \" only about 35 percents sought inpatient cares there and less than 10 percent used the hospitals when needing surgeries with any kind. \"']\n",
            "Prediction: 50 percent of the residents used the emergency departments, and only about 35 percent of the residents sought inpatient care there and less than 10 percent used the hospitals when needed.\n",
            "Reference: ['Their research showed that before Hurricane Sandy, only \" about 50 percent of residents used the emergency department \" and \" only about 35 percent sought inpatient care there, and less than 10 percent used the hospital when needing surgery of any kind. \"']\n",
            "----------------------------------------\n",
            "Sample 3:\n",
            "Source: ['Fix grammar: It been widely blelieved tha every student interested within some subject which might not be interested by other students so it is difficult to forced students to study subjects which they unwilling to study it, otherwise they will fail in it and because of that they will feel disappointed to do any thing and this a significant issue.']\n",
            "Prediction:  It was widely believed that every student interested in some subject which might not be interested by other students, so it was difficult to force students to study subjects which they are not interested in, otherwise they would fail in it and because of that, they will feel disappointed to do any thing and this a significant issue.\n",
            "Reference: ['It is widely believed that every student should be interested in some subjects which might not be interesting to other students so it is difficult to force students to study subjects which they are unwilling to study, otherwise they will fail at them and because of that they will feel too disappointed to do anything and this a significant issue.']\n",
            "----------------------------------------\n",
            "Sample 4:\n",
            "Source: ['Fix grammatical errors: This is why I totally agree like the following comments: \" My upbringings teaches me to been calm and easy-going - I really appreciate but now \". First of all, I agree with this person including I think that the ways someones has been brought having a great influence on his life.']\n",
            "Prediction: \n",
            "This is why I totally agree like the following comments: \" My upbringings teaches me to be calm and easy-going - I really appreciate but now \".\n",
            "Reference: ['This is why I totally agree with the following comment: \" My upbringing taught me to be calm and easy-going - I really appreciate that now. \" First of all, I agree with this person because I think that the way someone has been brought up has a great influence on his life.']\n",
            "----------------------------------------\n",
            "Sample 5:\n",
            "Source: [\"Fix grammaticality in this sentence: yesterday I went after the Center shopping before some friends, I really enjoyed it, I liked to buy new clothes for me, it's my best hobbie, the problem is that I doesn't have so much money now, I think I'll ask for it despite my father, I need more clothes, I'm planned to goes of the shopping again tomorrows, maybe today beyond the afternoon.\"]\n",
            "Prediction: \n",
            "esterday, I went after the Center shopping before some friends, I really enjoyed it, I liked to buy new clothes for me, it's my best hobbie, the problem is that I don't have so much money now, I think I'll ask for it despite my father, I need more clothes, I'm planning to go back to the shopping again tomorrow, maybe today beyond the afternoon.\n",
            "Reference: [\"Yesterday I went to the shopping centre with some friends. I really enjoyed it, I like to buy new clothes for me, it's my best hobby, the problem is that I don't have very much money now. I think I'll ask my father for some. I need more clothes. I'm planning to go to the shopping centre again tomorrow, or maybe today in the afternoon.\"]\n",
            "----------------------------------------\n",
            "Sample 6:\n",
            "Source: [\"Fix grammatical errors: I've checked the prices as well it's about £2000 for the whole sets (We can all shared the money) I are really sorry, but I couldn't come and help the day before, I've gotta help my parents out, because they are goes out within the weekend.\"]\n",
            "Prediction: I've checked the prices as well, it's about £2000 for the whole sets (We can all share the money). I'm really sorry, but I couldn't come and help my parents out, because they are going out within the weekend.\n",
            "Reference: [\"I've checked the price as well it's about £2000 for the whole set. (We can all share the cost). I'm really sorry, but I can't come and help the day before. I've gotta help my parents out, because they are going away for the weekend.\"]\n",
            "----------------------------------------\n",
            "Sample 7:\n",
            "Source: [\"Make the sentence grammatical: I give this example because in many classes I had are I've seen teacher make decision throughout children based except their gender and it is not our place to make decisions after them.\"]\n",
            "Prediction:  I give this example because in many classes, I have seen a teacher make decisions throughout children based on their gender and it is not our place to make decisions after them.\n",
            "Reference: ['I give this example because, in many classes, I saw teachers make decisions for children based on gender, and it is not in our position to make decisions for them.']\n",
            "----------------------------------------\n",
            "Sample 8:\n",
            "Source: [\"Fix grammatical mistakes in this sentence: I know how worried you are, take it easy! , if you like the countryside you've better to go to a small schools, but I thought around it are not the best choice for you because you like noise, cars and tecnology, so I think you will choose the centre along town, downoff additions you like the large buildings because you like running along the areas, don't you?\"]\n",
            "Prediction:  I know how worried you are, take it easy!, if you like the countryside, you've better to go to a small schools, but I think you will choose the centre along town, downoff additions, because you like running along the areas, don't you?\n",
            "Reference: [\"I know how worried you are, but take it easy! If you like the countryside you'd better go to a small school, but I think that it is not the best choice for you because you like noise, cars and technology, so I think you should choose the centre of town, in addition, you like large buildings because you like running around the area, don't you?\"]\n",
            "----------------------------------------\n",
            "Sample 9:\n",
            "Source: ['Make the sentence grammatical: I realized beyond this attitude would destroy me, and at this points my views of happiness shifted in a more realistic way, acknowledging happiness was step through steps process of overcoming challenge.']\n",
            "Prediction:  I realized beyond this attitude would destroy me, and at this points my views of happiness shifted in a more realistic way, acknowledging happiness was a step through the process of overcoming the challenge.\n",
            "Reference: ['I realized that that attitude would destroy me, and at that point, my view of happiness shifted; acknowledging happiness was a step-by-step process of overcoming challenges.']\n",
            "----------------------------------------\n",
            "Sample 10:\n",
            "Source: ['Make the sentence grammatical: When you will deeply thought about positive thing you will found another advantages like you solving actually any problem or troubles which you have, and I can forget to mention the most important thing and it is called beyond help of phone. before example: ambulance, firemen, police and other emergency service.']\n",
            "Prediction:  When you will deeply think about positive things, you will find another advantage like you solving actually any problem or troubles which you have, and I can forget to mention the most important thing and it is called beyond help of the phone. before example: ambulance, firemen, police, and other emergency service.\n",
            "Reference: ['When you think deeply about positive things you will find another advantage, you can solve actually any problem or trouble which you have, and I forgot to mention the most important thing and that is calling for help with the phone. For example, the ambulance, firemen, police and other emergency services.']\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2 Create a preference optimization dataset [5 points]**\n",
        "\n",
        "* *Generate Output Variants* -- for each input sentence in the training set, use the fine-tuned model to generate two different output variants.\n",
        " * Consider using different decoding strategies, such as varying the temperature or beam size, to produce diverse outputs. Select an approach based on the desired balance between diversity and quality.\n",
        "\n",
        "* *Preference Annotation* -- measure the edit distance between each **generated predicted variant** and **ground truth correction**. Label the variant with the lower edit distance as \"chosen\" and the one with the higher edit distance as \"rejected.\"\n",
        " * Beyond using edit distance, what other metrics or methods could you consider to do preference dataset annotation?\n"
      ],
      "metadata": {
        "id": "MNL0C_cnoV0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Report on Part 2.2:\n",
        "\n",
        "- *Generate Output Variants:*\n",
        "\n",
        "    To ensure diversity and quality, I played with distinctive decoding strategies including **[Greedy Search], [Beam Search], [Sampling with temperature], [Top-P sampling]** as shown below. You can freely choose 2 or more than 2 decoding_methods to generate candidate outputs, then the candidate outputs with the largest/smallest edit_distance to the target groundtruth are selected as th chosen/rejected pair.\n",
        "\n",
        "    - To ensure inter-output diversity and quality, the final preference_dataset is created on the two **`decoding_methods=['greedy', 'sampling']`**. Greedy search is computationally efficient compared to other methods, while random sampling with a high temperature ensures diversity and differentiability from the other methods.\n",
        "\n",
        "    - To ensure intra-output quality (and diversity), I curated a decent set of hyperprameters for each decoding methods.\n",
        "\n",
        "    - In practice, apart from varying decoding strategies, it is also a competent approach to generate diversely high-quality preference data by randomly selecting few-shot examples from a pool that are prompted to LLMs for diverse generations.\n",
        "\n",
        "- *Preference Annotation*:\n",
        "\n",
        "    - Beyond using edit distance, for this project, BLEU score would be another suitable automatic metic, especially considering it is the metric for evaluating the SFT (and later DPO-trained) model.\n",
        "\n",
        "    - The LLM-AS-JUDGE evaluation method is another automatic metric in evaluating the closeness between a model-generated sequence with the groundtruth sequence. We can even make this a more fine-grained and domain-specific evaluatoin metric, e.g., by instructing the LLM evaluator to judge in the aspect of grammaticality.\n",
        "\n",
        "- *Visualization*:\n",
        "\n",
        "    - **Diversity**: As shown from the visualization, the differentiability of the chosen/rejected pair in the generated preference dataset is not too high; however, none of the chosen/rejected output are identical. There are observably stable nuances in grammaticality.\n",
        "    - **Quality**: Both chosen/rejected output are in good format, generally following the input and performing the grammatical error correction task.\n",
        "    - **Annotation**: The preferential annotations are relatively consistent: with each of the five samples, the chosen output has a minor yet explicit edge over the rejected output in being closer to target output.\n",
        "\n"
      ],
      "metadata": {
        "id": "F1Yhn1yz6hMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fast_edit_distance\n",
        "from fast_edit_distance import edit_distance\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "\n",
        "# Generate Output Variants and Annotate Preferences\n",
        "def generate_annotate_preference(model, tokenizer, dataset, seed=42,\n",
        "                               batch_size=32, decoding_methods=['greedy', 'top-p'], input_max_length=256, max_new_tokens=256,\n",
        "                               num_beams=2, no_repeat_ngram_size=6,     # Beam Search hp\n",
        "                               temperature=0.7,                         # Sampling with temperature hp\n",
        "                               top_p=0.92):                             # Top-p sampling hp\n",
        "    preference_data = []\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    for i in tqdm(range(0, len(dataset), batch_size), desc=\"Generating Preferences\"):\n",
        "        batch = dataset[i : i + batch_size]\n",
        "        input_texts = batch['prompt']\n",
        "        inputs = tokenizer(input_texts, return_tensors=\"pt\", padding='longest', truncation=True, max_length=input_max_length).to(device)\n",
        "\n",
        "        for k in range(len(batch['prompt'])):\n",
        "            output_variants = {}  # To store generated variants for this prompt\n",
        "\n",
        "            # --- Decoding ---\n",
        "            for method in decoding_methods:\n",
        "\n",
        "                # Generate outputs with different decoding strategies\n",
        "                if method == 'greedy':  # Greedy Search\n",
        "                    generated_ids = model.generate(\n",
        "                        **inputs, max_new_tokens=max_new_tokens, eos_token_id=tokenizer.eos_token_id, repetition_penalty=1.0,\n",
        "                        do_sample=False, num_beams=1\n",
        "                    )\n",
        "                elif method == 'beam':  # Beam Search\n",
        "                    generated_ids = model.generate(\n",
        "                        **inputs, max_new_tokens=max_new_tokens, eos_token_id=tokenizer.eos_token_id, repetition_penalty=1.0,\n",
        "                        num_beams=num_beams, early_stopping=True, num_return_sequences=1\n",
        "                    )\n",
        "                elif method == 'sampling':  # Sampling with temperature\n",
        "                    generated_ids = model.generate(\n",
        "                        **inputs, max_new_tokens=max_new_tokens, eos_token_id=tokenizer.eos_token_id, repetition_penalty=1.0,\n",
        "                        top_k=0, temperature=temperature, do_sample=True\n",
        "                    )\n",
        "                elif method == 'top-p':  # Top-p sampling\n",
        "                    generated_ids = model.generate(\n",
        "                        **inputs, max_new_tokens=max_new_tokens, eos_token_id=tokenizer.eos_token_id, repetition_penalty=1.0,\n",
        "                        top_k=0, top_p=top_p, do_sample=True\n",
        "                    )\n",
        "                else:\n",
        "                    raise ValueError(f\"Unknown decoding method: {method}\")\n",
        "\n",
        "                # Batch decode and extract the generated text\n",
        "                generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "                extracted_outputs = [extract_output(generated_text) for generated_text in generated_texts] # per method, len(extracted_outputs) = batch_size\n",
        "                output_variants[method] = extracted_outputs\n",
        "\n",
        "            # --- Calculate Edit Distances and Determine Preferences ---\n",
        "            for k in range(len(batch['prompt'])):  # Iterate through each sample in the batch\n",
        "                edit_distances = {}\n",
        "                for method, outputs in output_variants.items():\n",
        "                    edit_distances[method] = edit_distance(outputs[k], batch['tgt'][k])\n",
        "\n",
        "                # Find methods with minimum and maximum edit distances for this sample\n",
        "                chosen_method = min(edit_distances, key=edit_distances.get)\n",
        "                rejected_method = max(edit_distances, key=edit_distances.get)\n",
        "\n",
        "                preference_data.append({\n",
        "                    'prompt': input_texts[k],\n",
        "                    'tgt': batch['tgt'][k],\n",
        "                    'chosen': output_variants[chosen_method][k],\n",
        "                    'rejected': output_variants[rejected_method][k],\n",
        "                    'chosen_method': chosen_method,\n",
        "                    'rejected_method': rejected_method\n",
        "                })\n",
        "\n",
        "        return Dataset.from_list(preference_data)"
      ],
      "metadata": {
        "id": "krzvaoN-o5mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to load the saved SFT_model model:\n",
        "SFT_model_name = '/content/drive/MyDrive/Application/C4AI/SFT_512_16_1e-5_epoch3_new'  # Your saved model path\n",
        "SFT_model = AutoModelForCausalLM.from_pretrained(SFT_model_name).to(device)\n",
        "\n",
        "# Create PO dataset by generating preference data\n",
        "preference_dataset = generate_annotate_preference(SFT_model, tokenizer, train_ds, seed=42,\n",
        "                                                  batch_size=160, decoding_methods=['greedy', 'sampling'],  # Choose at least two methods from ['greedy', 'top-p', 'sampling', 'beam']\n",
        "                                                  input_max_length=256, max_new_tokens=256,            # set max seq based on train_ds length stats\n",
        "                                                  num_beams=2, no_repeat_ngram_size=6,                 # Beam Search hp\n",
        "                                                  temperature=0.7,                                     # Sampling with temperature hp\n",
        "                                                  top_p=0.92)                                          # Top-p sampling hp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SL9c_2r1FWJP",
        "outputId": "3f4eee38-ef91-4a19-be5d-75e50c3ca75c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Preferences:   0%|          | 0/124 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Generating Preferences:   0%|          | 0/124 [49:00<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: This dataset is uploaded at huggingface for easy loading: \"alisa-yingjia-wan/gec_SmolLM_DPO\".\n",
        "\n",
        "To load preference_dataset:\n",
        "```\n",
        "from datasets import load_dataset\n",
        "\n",
        "preference_dataset = load_dataset(\"alisa-yingjia-wan/gec_SmolLM_DPO\")\n",
        "```"
      ],
      "metadata": {
        "id": "1-ZBYV79Lvfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: (Load and) Visualize the created dataset -- display at least 5 lines of the dataset.\n",
        "\n",
        "for i in range(5):  # Display the first 5 examples\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"Input Text: {preference_dataset[i]['prompt']}\")\n",
        "    print(f\"Target: {preference_dataset[i]['tgt']}\")\n",
        "    print(f\"Chosen: {preference_dataset[i]['chosen']}\")\n",
        "    print(f\"Rejected: {preference_dataset[i]['rejected']}\")\n",
        "    print(f\"Chosen Method: {preference_dataset[i]['chosen_method']}\")\n",
        "    print(f\"Rejected Method: {preference_dataset[i]['rejected_method']}\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "\n",
        "# self-added TODO: Beyond using edit distance, what other metrics or methods could you consider to do preference dataset annotation?\n"
      ],
      "metadata": {
        "id": "mcPiDof4iLNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36426653-3135-47ea-b508-1323000795c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "Input Text: Remove all grammatical errors from this text: For example, countries with a lot of deserts can terraform their desert to increase their habitable land and using irrigation to provide clean water to the desert.. \n",
            "Answer: \n",
            "Target: For example, countries with a lot of deserts can transform their desert to increase their habitable land and use irrigation to provide clean water to the desert.\n",
            "Chosen:  For example, countries with a lot of deserts can terraform their desert to increase their habitable land and using irrigation to provide clean water to the desert.\n",
            "Rejected:  For example, countries with a lot of deserts can terraform their deserts to increase their habitable land and using irrigation to provide clean water to the desert.\n",
            "Chosen Method: sampling\n",
            "Rejected Method: greedy\n",
            "--------------------\n",
            "Example 2:\n",
            "Input Text: Improve the grammaticality: As the number of people grows, the need of habitable environment is unquestionably essential.. \n",
            "Answer: \n",
            "Target: As the number of people grows, the need for a habitable environment is unquestionably increasing.\n",
            "Chosen:  As the number of people grows, the need for habitable environment is unquestionably essential.\n",
            "Rejected:  As the number of people grows, the need for a habitable environment is undeniably essential.\n",
            "Chosen Method: greedy\n",
            "Rejected Method: sampling\n",
            "--------------------\n",
            "Example 3:\n",
            "Input Text: Improve the grammaticality of this sentence: Besides some technologically determinists that allow the development of biometric identification, this technology is also shaped by three social factors, namely, the desire of the society for safety, convenience and economy.. \n",
            "Answer: \n",
            "Target: Besides some technological determinists that allow the development of biometric identification, this technology is also shaped by three social factors, namely, the desire of society for safety, convenience, and economy.\n",
            "Chosen:  Besides some technologically determinists that allow the development of biometric identification, this technology is also shaped by three social factors, namely, the desire of the society for safety, convenience, and economy.\n",
            "Rejected:  Besides some technologically determinists that allow the development of biometric identification, this technology is also shaped by three social factors: the desire of the society for safety, convenience, and economy.\n",
            "Chosen Method: greedy\n",
            "Rejected Method: sampling\n",
            "--------------------\n",
            "Example 4:\n",
            "Input Text: Remove all grammatical errors from this text: Safety is one of the crucial problems that many countries and companies concern.. \n",
            "Answer: \n",
            "Target: Safety is one of the crucial problems that many countries and companies are concerned about.\n",
            "Chosen:  Safety is one of the crucial problems that many countries and companies concern about.\n",
            "Rejected:  Safety is one of the crucial problem that many countries and companies concern about.\n",
            "Chosen Method: greedy\n",
            "Rejected Method: sampling\n",
            "--------------------\n",
            "Example 5:\n",
            "Input Text: Fix grammaticality in this sentence: On one hand more and more virus and hack can access personal computers, so the secret data and documents may be stolen.. \n",
            "Answer: \n",
            "Target: On the one hand, more and more viruses and hackers can access personal computers, so secret data and documents may be stolen.\n",
            "Chosen:  On the other hand, more and more viruses and hacks can access personal computers, so secret data and documents may be stolen.\n",
            "Rejected:  On the other hand, more and more viruses and hackers can access personal computers, so the secret data and documents may be stolen.\n",
            "Chosen Method: sampling\n",
            "Rejected Method: greedy\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.3 Run Direct Preference Optimization (DPO) [5 points]**\n",
        "* Use the preference optimization dataset to further train the model through DPO, a method that leverages human-like preferences for model training.\n",
        "* After running DPO, measure the BLEU score on the test set. Compare this performance to the baseline established during the SFT phase.\n",
        "* Search for an optimal set of hyperparameters, such as the learning rate and number of epochs. We provide an estimated BLEU score that you should aim to achieve after one epoch. However, you may achieve a better score by finding the most suitable hyperparameters."
      ],
      "metadata": {
        "id": "s2uLgjo7oaaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report on Part 2.3:\n",
        "\n",
        "Through multiple 1-epoch trials, I found that the optimal learning rates in DPO training on my preference dataset converge towards a smaller value (1e-6).\n",
        "\n",
        "The BLEU score gains of DPO-SFT model (0.4747) over the SFT_model (0.4546) shows that the DPO training pipeline increases model performance. The preference information empowers the model in aligning with better output in grammatical error function. This also provides a certain degree of validity in my preference dataset generated by choosing from different decoding strategies.\n",
        "\n",
        "However, It is noteworthy that both the preference data annotation and the model evaluation is measured by automatic metrics (edit_distance and BLEU). Therefore, qualitative analysis and mannual output inspection is crucial (to be reported in Part 3)."
      ],
      "metadata": {
        "id": "oYBn4pGhQ6v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DPOTrainer: https://huggingface.co/docs/trl/en/dpo_trainer#trl.DPOTrainer\n",
        "# DPOConfig: https://huggingface.co/docs/trl/en/dpo_trainer#trl.DPOConfig\n",
        "import os\n",
        "from trl import DPOConfig, DPOTrainer\n",
        "\n",
        "# TODO: Run Direct Preference Optimization (DPO)\n",
        "\n",
        "# load dataset\n",
        "from datasets import load_dataset\n",
        "preference_dataset = load_dataset(\"alisa-yingjia-wan/gec_SmolLM_DPO\")\n",
        "\n",
        "# load model, innitialized from SFT_model\n",
        "SFT_directory = '/content/drive/MyDrive/Application/C4AI/SFT_512_16_1e-5_epoch3_new'\n",
        "DPO_model = AutoModelForCausalLM.from_pretrained(SFT_directory).to(device)\n",
        "\n",
        "training_args = DPOConfig(\n",
        "    beta=0.1, # beta is the temperature parameter for the DPO loss, typically between 0.1 to 0.5. We ignore the reference model as beta -> 0.\n",
        "    loss_type=\"sigmoid\", # the DPO authors propose the sigmoid loss on the normalized likelihood via the logsigmoid to fit a logistic regression\n",
        "    # max_length=512,\n",
        "    max_prompt_length=256,\n",
        "    max_target_length=256,\n",
        "    per_device_train_batch_size=16,   # Batch size for training\n",
        "    learning_rate=1e-6,\n",
        "    num_train_epochs=1,\n",
        "    output_dir=\"/tmp/DPO\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "dpo_trainer = DPOTrainer(\n",
        "    DPO_model,\n",
        "    args=training_args,\n",
        "    train_dataset=preference_dataset['train'],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "dpo_trainer.train()"
      ],
      "metadata": {
        "id": "36t5EBK8o_sE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378,
          "referenced_widgets": [
            "18daca22c45f4fe98849abb676e87c76",
            "fae0bb6d7feb45d18652036c56397a6b",
            "8546b06246da42fc9232d54d143d89a0",
            "2c714db491a94069bf4dd9d280faa33f",
            "5178603cb8ee4975ad7a7b77f7eaf283",
            "6ac669f5c06c40a7a7037190f18697b1",
            "07a8c3baa6c64858b663d0e55fa3baf0",
            "3839c37d810349a1acb59a58818d3018",
            "d3752c3b189d408b8923b4e972b43d51",
            "929e4aff94f643d696a66d39dfa77094",
            "5543b9e5555e49459d70da02502373b6"
          ]
        },
        "outputId": "0a2c78a8-5349-4370-90f6-d0488d0ee5b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:671: UserWarning: `max_length` is not set in the DPOConfig's init it will default to `512` by default, but you should do it yourself in the future.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:719: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/25600 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18daca22c45f4fe98849abb676e87c76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1600' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1600/1600 06:16, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.626000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.564400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.539300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1600, training_loss=0.5743206834793091, metrics={'train_runtime': 376.6671, 'train_samples_per_second': 67.965, 'train_steps_per_second': 4.248, 'total_flos': 0.0, 'train_loss': 0.5743206834793091, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DPO_model\n",
        "DPO_directory = '/content/drive/MyDrive/Application/C4AI/DPO_256_16_5e-6_epoch1_new'\n",
        "save_trainer_checkpoint(dpo_trainer, DPO_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlmBNmZoAhEe",
        "outputId": "36f4991d-dfc1-4496-e149-afb4dd8eb2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/drive/MyDrive/Application/C4AI/DPO_256_16_5e-6_epoch1_new!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Evaluate model, use evaluate_model function\n",
        "# toy_val_ds = val_ds.select(range(20))\n",
        "dpo_bleu_score = evaluate_model(DPO_model, tokenizer, val_ds, output_file=\"/tmp/DPO_validation_output.json\", max_length=512, max_new_tokens=256)\n",
        "print(f\"BLEU score on validation set after DPO training: {dpo_bleu_score}\")"
      ],
      "metadata": {
        "id": "9ST7kFAOhmOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3212785-4b47-43b4-d77f-9625700bc951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2888: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score on validation set after DPO training: 0.4747308567097804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected BLEU score after 1 epoch SFT + DPO is ~ 0.50."
      ],
      "metadata": {
        "id": "pffG5Flhb5Nu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Coding Challenge Part 3: Explore Alternative DPO Variants for Improved Model Performance [10 points]**"
      ],
      "metadata": {
        "id": "UeBKJjRjsfHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider employing a different version or variant of DPO. Your task is to:\n",
        "\n",
        "* Choose a variant of DPO or another preference-based optimization method that could potentially enhance the model's performance.\n",
        "* Describe the specific differences in this approach compared to the initial DPO method used.\n",
        "* Train the model using this alternative DPO method and measure its performance on the test set using the BLEU score.\n",
        "* Compare these results with the baseline performance achieved during the initial Supervised Fine-Tuning (SFT) and the first DPO implementation.\n",
        "* Select a few GEC example after SFT, DPO and this DPO variant phases and compare the quality of the corrections, which one you prefer as human?\n",
        "* You are allowed to make changes in the preference data annotation to improve the score, e.g. apply different metrics or methods beyond edit distance.\n",
        "* Discuss the role of any changes in achieving these results. Consider potential trade-offs or limitations introduced by the new approach."
      ],
      "metadata": {
        "id": "Z6KoS4jB01WW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report on Part 3:\n",
        "\n",
        "- I chose **[Robust DPO](https://arxiv.org/pdf/2403.00409)** as the Alternative DPO method to potentially enhance the model's performance. Below is the code for its Robust DPO training implementation.\n",
        "\n",
        "    (The main rationale for choosing Robust DPO is because of the potential high noise level of my the preference dataset. It is reported in the paper that the performance of DPO drops significantly when the noise rates are high, which describes a big concern for my DPO pipeline.\n",
        "    \n",
        "    Firstly, due to the dataset nature of being annotated by a simple automatic metric edit_distance, the annotated chosen/rejected pairs do not always accurately reflect a good comparison for preference, thus contributing to preferential noise.\n",
        "\n",
        "    Secondly, the output variants were generated via various decoding strategies which may suffer from diversity: the two be both valid but only differ slightly in phrasing, hence contributing to ambiguous or arbituary preferences. This can also introduce inconsistency into the DPO training process.)\n",
        "\n",
        "\n",
        "- Differences between the two approaches:\n",
        "    1. The main differences is in the DPO loss function: *DPO* is grounded in the log-sigmoid loss function, which optimizes the model based on the relative likelihood of preferred vs. non-preferred completions. It directly learns from the preference pairs without considering noise. In comparison, *Robust DPO* adopts a smoothed likelihood ratio with noise, accounting for labeling errors and adjusts its training process accordingly. The `label smoothing` techniques model loss to prevent overconfidence and improve robustness to noisy data.\n",
        "\n",
        "    2. Assumptions: DPO using sigmoid loss function applies generally as a starting baseline, while Robust DPO modifies the DPO loss to account for noise, based on the assumption that preferences are probabilistic rather than binary.\n",
        "\n",
        " (Results and Discussions are continued in the next text block.)"
      ],
      "metadata": {
        "id": "0maPGrERGjR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DPO variant reference doc: https://huggingface.co/docs/trl/en/dpo_trainer#loss-functions\n",
        "# PEFT: https://huggingface.co/docs/trl/en/dpo_trainer#reference-model-considerations-with-peft\n",
        "# DPOTrainer: https://huggingface.co/docs/trl/en/dpo_trainer#trl.DPOTrainer\n",
        "# DPOConfig: https://huggingface.co/docs/trl/en/dpo_trainer#trl.DPOConfig\n",
        "\n",
        "# TODO: Run Robust DPO:\n",
        "\n",
        "# load robust DPO_model, innitialized from SFT_model\n",
        "SFT_directory = '/content/drive/MyDrive/Application/C4AI/SFT_512_16_1e-5_epoch3_new'\n",
        "rDPO_model = AutoModelForCausalLM.from_pretrained(SFT_directory).to(device)\n",
        "\n",
        "training_args = DPOConfig(\n",
        "    beta=0.1,           # beta is the temperature parameter for the DPO loss, typically between 0.1 to 0.5.\n",
        "    loss_type=\"robust\",  # Robust DPO\n",
        "    label_smoothing=0.2, # Robust DPO hp (0 measn stardard DPO), 0.5 indicates high uncertainty or noise in the labels.\n",
        "    # max_length=512,\n",
        "    max_prompt_length=256,\n",
        "    max_target_length=256,\n",
        "    per_device_train_batch_size=16,   # Batch size for training\n",
        "    learning_rate=1e-6,\n",
        "    num_train_epochs=1,\n",
        "    output_dir=\"/tmp/rDPO\",\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "dpo_trainer = DPOTrainer(\n",
        "    rDPO_model,\n",
        "    args=training_args,\n",
        "    train_dataset=preference_dataset['train'],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "dpo_trainer.train()"
      ],
      "metadata": {
        "id": "9AWhWy3fGcIE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499,
          "referenced_widgets": [
            "6cde311e0d6948d197d4bdd37075a4e9",
            "43c6da6c35314052a91cb576e3e4f9fb",
            "1af329647f13494a993295bb6645c3d5",
            "8feca2090ed641f68371d93ea56345aa",
            "9d5c47a69c4c40d9afb1ddbc5f86a760",
            "32bd8246889e4dc0981a491c9ab94c71",
            "a535c3521fb4430bbe700785ff8cef53",
            "b5465687ec934ea49184c18c7a2602f7",
            "db835d03d55e4cd5becbd47f92ecdb5e",
            "682a48aefd1443d297c4a989f111cd7b",
            "a5292e3ad34b4564a2aa3d1fce5e9c00"
          ]
        },
        "outputId": "42004dd0-5fe6-4cda-fbc5-c842ab871f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:671: UserWarning: `max_length` is not set in the DPOConfig's init it will default to `512` by default, but you should do it yourself in the future.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:719: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cde311e0d6948d197d4bdd37075a4e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/25600 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1068' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1068/1600 04:11 < 02:05, 4.23 it/s, Epoch 0.67/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.544100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.338500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1600' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1600/1600 06:20, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.544100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.338500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.221800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1600, training_loss=0.35951624512672425, metrics={'train_runtime': 381.1598, 'train_samples_per_second': 67.163, 'train_steps_per_second': 4.198, 'total_flos': 0.0, 'train_loss': 0.35951624512672425, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE rDPO_model at rDPO_directory\n",
        "\n",
        "rDPO_directory = '/content/drive/MyDrive/Application/C4AI/rDPO_256_16_1e-6_epoch1_new'\n",
        "save_trainer_checkpoint(dpo_trainer, rDPO_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Epcr5SDBqjXP",
        "outputId": "b9d48a8d-0756-43ba-ce57-c7ea9328eae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/drive/MyDrive/Application/C4AI/rDPO_256_16_1e-6_epoch1_new!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the RobustDPO model on bleu\n",
        "\n",
        "# toy_val_ds = val_ds.select(range(20))\n",
        "rdpo_bleu_score = evaluate_model(rDPO_model, tokenizer, val_ds, output_file=\"/tmp/rDPO_validation_output.json\", max_length=512, max_new_tokens=256)\n",
        "print(f\"BLEU score on validation set after robust DPO training: {rdpo_bleu_score}\")"
      ],
      "metadata": {
        "id": "B3bmlbaAKa7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a781de-cc7b-4987-bb55-1ec4813ae147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score on validation set after robust DPO training: 0.4538686969060181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save _validation_outputs\n",
        "\n",
        "import json\n",
        "\n",
        "models = ['SFT', 'DPO', 'rDPO']\n",
        "\n",
        "for model in models:\n",
        "    tmp_json = f'/tmp/{model}_validation_output.json'\n",
        "    file_path = f'/content/drive/MyDrive/Application/C4AI/{model}_validation_output.json'\n",
        "\n",
        "    # Read data from the temporary JSON file\n",
        "    with open(tmp_json, 'r') as tmp_file:\n",
        "        data = json.load(tmp_file)\n",
        "\n",
        "    # Write data to the final JSON file\n",
        "    with open(file_path, 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)"
      ],
      "metadata": {
        "id": "TSDu9BoIYSqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Qualitative case study: See report below for my preference annotation.\n",
        "\n",
        "import json\n",
        "\n",
        "def load_and_read_samples(models, base_path, num_samples=5):\n",
        "    # Initialize a dictionary to store predictions\n",
        "    predictions_dict = {}\n",
        "\n",
        "    # Load the validation output files for each model\n",
        "    for model in models:\n",
        "        file_path = f\"{base_path}/{model}_validation_output.json\"\n",
        "        with open(file_path, \"r\") as f:\n",
        "            output = json.load(f)\n",
        "        predictions_dict[model] = output[\"pred\"]\n",
        "\n",
        "    sources = output['src']\n",
        "    references = output[\"tgt\"]\n",
        "\n",
        "    # Read the first num_samples samples\n",
        "    for i in range(num_samples):\n",
        "        print(f\"Sample {i + 1}:\")\n",
        "        print(f\"Source: {sources[i]}\")\n",
        "        print(f\"Reference: {references[i]}\")\n",
        "\n",
        "        for model in models:\n",
        "            print(f\"{model} Prediction: {predictions_dict[model][i]}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "# Specify the models and base path\n",
        "models = ['SFT', 'DPO', 'rDPO']\n",
        "base_path = \"/content/drive/MyDrive/Application/C4AI\"\n",
        "\n",
        "# Compare predictions for 5 samples\n",
        "load_and_read_samples(models, base_path, num_samples=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS39hagwKGWi",
        "outputId": "f9b93129-432e-4a5c-aea9-c8aafc854a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1:\n",
            "Source: ['Fix grammaticality: First of all, from you read just to found in the poems or novel what well-known critic have already found out, you looses the pleasures of reading something which is expecting to be a new experience to you.']\n",
            "Reference: ['First of all, if you read just to find in the poem or novel what well-known critics have already found out, you lose the pleasure of reading something that is expected to be a new experience to you.']\n",
            "SFT Prediction:  First of all, from you, I read just to find out what well-known critic has already found out, you have lost the pleasures of reading something which is expecting to be a new experience to you.\n",
            "DPO Prediction:  First of all, from you read just to find out the poems or novel what well-known critic have already found out, you lose the pleasures of reading something which is expecting to be a new experience to you.\n",
            "rDPO Prediction:  First of all, from you read just to find in the poems or novel what well-known critic have already found out, you loosed the pleasures of reading something which is expecting to be a new experience to you.\n",
            "----------------------------------------\n",
            "Sample 2:\n",
            "Source: ['Fix grammatical errors: Their research shown that before Hurricane Sandy only \" about 50 percent during resident used the emergency departments, \" and \" only about 35 percents sought inpatient cares there and less than 10 percent used the hospitals when needing surgeries with any kind. \"']\n",
            "Reference: ['Their research showed that before Hurricane Sandy, only \" about 50 percent of residents used the emergency department \" and \" only about 35 percent sought inpatient care there, and less than 10 percent used the hospital when needing surgery of any kind. \"']\n",
            "SFT Prediction: 50 percent of the residents used the emergency departments, and only about 35 percent of the residents sought inpatient care there and less than 10 percent used the hospitals when needed.\n",
            "DPO Prediction: Their research showed that before Hurricane Sandy only \" about 50 percent during the resident used the emergency departments, \" and \" only about 35 percent sought inpatient cares there and less than 10 percent used the hospitals when needed with any kind. \".\n",
            "rDPO Prediction: \n",
            "Answer: \n",
            " cloze: Their research showed that before Hurricane Sandy only \" about 50 percent during resident used the emergency departments, \" and \" only about 35 percent sought inpatient cares there and less than 10 percent used the hospitals when needed to surgery with any kind.\n",
            "----------------------------------------\n",
            "Sample 3:\n",
            "Source: ['Fix grammar: It been widely blelieved tha every student interested within some subject which might not be interested by other students so it is difficult to forced students to study subjects which they unwilling to study it, otherwise they will fail in it and because of that they will feel disappointed to do any thing and this a significant issue.']\n",
            "Reference: ['It is widely believed that every student should be interested in some subjects which might not be interesting to other students so it is difficult to force students to study subjects which they are unwilling to study, otherwise they will fail at them and because of that they will feel too disappointed to do anything and this a significant issue.']\n",
            "SFT Prediction:  It was widely believed that every student interested in some subject which might not be interested by other students, so it was difficult to force students to study subjects which they are not interested in, otherwise they would fail in it and because of that, they will feel disappointed to do any thing and this a significant issue.\n",
            "DPO Prediction:  It been widely believed that every student interested in some subject which might not be interested by other students so it is difficult to force students to study subjects which they unwilling to study it, otherwise they will fail in it and because of that they will feel disappointed to do any thing and this a significant issue.\n",
            "rDPO Prediction:  It been widely blelieved that every student interested within some subject which might not be interested by other students so it is difficult to force students to study subjects which they unwilling to study it, otherwise they will fail in it and because of that they will feel disappointed to do any thing and this a significant issue.\n",
            "----------------------------------------\n",
            "Sample 4:\n",
            "Source: ['Fix grammatical errors: This is why I totally agree like the following comments: \" My upbringings teaches me to been calm and easy-going - I really appreciate but now \". First of all, I agree with this person including I think that the ways someones has been brought having a great influence on his life.']\n",
            "Reference: ['This is why I totally agree with the following comment: \" My upbringing taught me to be calm and easy-going - I really appreciate that now. \" First of all, I agree with this person because I think that the way someone has been brought up has a great influence on his life.']\n",
            "SFT Prediction: \n",
            "This is why I totally agree like the following comments: \" My upbringings teaches me to be calm and easy-going - I really appreciate but now \".\n",
            "DPO Prediction:  This is why I totally agree like the following comments: \" My upbringings teaches me to be calm and easy-going - I really appreciate but now \". First of all, I agree with this person including I think that the ways someones have been brought having a great influence on his life.\n",
            "rDPO Prediction: \n",
            "This is why I totally agree like the following comments: \" My upbringings teaches me to be calm and easy-going - I really appreciate but now \". First of all, I agree with this person including I think that the ways someones have been brought having a great influence on his life.\n",
            "----------------------------------------\n",
            "Sample 5:\n",
            "Source: [\"Fix grammaticality in this sentence: yesterday I went after the Center shopping before some friends, I really enjoyed it, I liked to buy new clothes for me, it's my best hobbie, the problem is that I doesn't have so much money now, I think I'll ask for it despite my father, I need more clothes, I'm planned to goes of the shopping again tomorrows, maybe today beyond the afternoon.\"]\n",
            "Reference: [\"Yesterday I went to the shopping centre with some friends. I really enjoyed it, I like to buy new clothes for me, it's my best hobby, the problem is that I don't have very much money now. I think I'll ask my father for some. I need more clothes. I'm planning to go to the shopping centre again tomorrow, or maybe today in the afternoon.\"]\n",
            "SFT Prediction: \n",
            "esterday, I went after the Center shopping before some friends, I really enjoyed it, I liked to buy new clothes for me, it's my best hobbie, the problem is that I don't have so much money now, I think I'll ask for it despite my father, I need more clothes, I'm planning to go back to the shopping again tomorrow, maybe today beyond the afternoon.\n",
            "DPO Prediction: \n",
            "Yesterday I went after the Center shopping before some friends, I really enjoyed it, I liked to buy new clothes for me, it's my best hobbie, the problem is that I doesn't have so much money now, I think I'll ask for it despite my father, I need more clothes, I'm planning to go again tomorrow, maybe today beyond the afternoon.\n",
            "rDPO Prediction: \n",
            "Yesterday I went after the Center shopping before some friends, I really enjoyed it, I liked to buy new clothes for me, it's my best hobbie, the problem is that I doesn't have so much money now, I think I'll ask for it despite my father, I need more clothes, I'm planning to go of the shopping again tomorrows, maybe today beyond the afternoon.\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report on Part 3 (Cont.)\n",
        "\n",
        "- Comparison of Results:\n",
        "\n",
        "    The evaluated BLEU scores on the validation set from SFT baseline model, SFT-DPO model, and SFT-Robust-DPO model are listed in the table below. There is an increase by adopting DPO to further train the SFT model. However, robust-DPO did not obtain a higher model performance compared to standard DPO.\n",
        "\n",
        "    On the one hand, the performance drop of Robust-DPO could be related to the quality of my preferecne dataset not being drastically noisy in preference labels. The applicability of robust-DPO relies on its assumption that the preference dataset suffers greatly from prefrential noise (e.g., arbituray preference annotations, undifferentiable chosen/rejected pairs). When the assumption fails, the robust loss function does not necessarily work so well;\n",
        "    \n",
        "    On the other hand, the lower performance of Robust-DPO may also arise from non-optimal set of hyperparameters. I used the same learning rate as DPO, and did not experiment with more choices of `beta` and `label_smoothing` due to time constraint. This could also be a major reason.\n",
        "\n",
        "\n",
        "| Model               | Epochs | BLEU Score |\n",
        "|---------------------|--------|------------|\n",
        "| SFT Model          | SFT: 3 | 0.4546     |\n",
        "| SFT-DPO Model        | +DPO: 1 | 0.4747     |\n",
        "| SFT-Robust-DPO Model | +R-DPO: 1 | 0.4539     |\n",
        "\n",
        "\n",
        "\n",
        "- Comparative Case Study on Models' Output:\n",
        "---\n",
        "| Model        | Prediction                                                                                                                                                                                              |\n",
        "|--------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **Target**   | First of all, if you read just to find in the poem or novel what well-known critics have already found out, you lose the pleasure of reading something that is expected to be a new experience to you. |\n",
        "| SFT          | First of all, from you, I read just to find out what well-known critic has already found out, you have lost the pleasures of reading something which is expecting to be a new experience to you.     |\n",
        "| DPO          | First of all, from you read just to find out the poems or novel what well-known critic have already found out, you lose the pleasures of reading something which is expecting to be a new experience to you. |\n",
        "| rDPO         | First of all, from you read just to find in the poems or novel what well-known critic have already found out, you loosed the pleasures of reading something which is expecting to be a new experience to you. |\n",
        "| **Sample 1 Preference** |     SFT                                                                                                                                                                                                   |\n",
        "\n",
        "\n",
        "| Model        | Prediction                                                                                                                                                                                                                                         |\n",
        "|--------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **Target**   | Their research showed that before Hurricane Sandy, only \" about 50 percent of residents used the emergency department \" and \" only about 35 percent sought inpatient care there, and less than 10 percent used the hospital when needing surgery of any kind. \" |\n",
        "| SFT          | 50 percent of the residents used the emergency departments, and only about 35 percent of the residents sought inpatient care there and less than 10 percent used the hospitals when needed.                                                            |\n",
        "| DPO          | Their research showed that before Hurricane Sandy only \" about 50 percent during the resident used the emergency departments, \" and \" only about 35 percent sought inpatient cares there and less than 10 percent used the hospitals when needed with any kind. \". |\n",
        "| rDPO         | Answer: \\n cloze: Their research showed that before Hurricane Sandy only \" about 50 percent during resident used the emergency departments, \" and \" only about 35 percent sought inpatient cares there and less than 10 percent used the hospitals when needed to surgery with any kind. |\n",
        "| **Sample 2 Preference** |          DPO                                                                                                                                                                                                                                                 |\n",
        "\n",
        "\n",
        "| Model        | Prediction                                                                                                                                                                                                                                         |\n",
        "|--------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **Target**   | It is widely believed that every student should be interested in some subjects which might not be interesting to other students so it is difficult to force students to study subjects which they are unwilling to study, otherwise they will fail at them and because of that they will feel too disappointed to do anything and this a significant issue. |\n",
        "| SFT          | It was widely believed that every student interested in some subject which might not be interested by other students, so it was difficult to force students to study subjects which they are not interested in, otherwise they would fail in it and because of that, they will feel disappointed to do any thing and this a significant issue. |\n",
        "| DPO          | It been widely believed that every student interested in some subject which might not be interested by other students so it is difficult to force students to study subjects which they unwilling to study it, otherwise they will fail in it and because of that they will feel disappointed to do any thing and this a significant issue. |\n",
        "| rDPO         | It been widely blelieved that every student interested within some subject which might not be interested by other students so it is difficult to force students to study subjects which they unwilling to study it, otherwise they will fail in it and because of that they will feel disappointed to do any thing and this a significant issue. |\n",
        "| **Sample 3 Preference** |        SFT                                                                                                                                                                                                                                                   |\n",
        "\n",
        "| Model        | Prediction                                                                                                                                                                                                                                         |\n",
        "|--------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **Target**   | This is why I totally agree with the following comment: \" My upbringing taught me to be calm and easy-going - I really appreciate that now. \" First of all, I agree with this person because I think that the way someone has been brought up has a great influence on his life. |\n",
        "| SFT          | This is why I totally agree like the following comments: \" My upbringings teaches me to be calm and easy-going - I really appreciate but now \".                                                                                                        |\n",
        "| DPO          | This is why I totally agree like the following comments: \" My upbringings teaches me to be calm and easy-going - I really appreciate but now \". First of all, I agree with this person including I think that the ways someones have been brought having a great influence on his life. |\n",
        "| rDPO         | This is why I totally agree like the following comments: \" My upbringings teaches me to be calm and easy-going - I really appreciate but now \". First of all, I agree with this person including I think that the ways someones have been brought having a great influence on his life. |\n",
        "| **Sample 4 Preference** |       DPO = DPO                                                                                                                                                                                                                                                    |\n",
        "\n",
        "| Model        | Prediction                                                                                                                                                                                                                                            |\n",
        "|--------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **Target**   | Yesterday I went to the shopping centre with some friends. I really enjoyed it, I like to buy new clothes for me, it's my best hobby, the problem is that I don't have very much money now. I think I'll ask my father for some. I need more clothes. I'm planning to go to the shopping centre again tomorrow, or maybe today in the afternoon. |\n",
        "| SFT          | esterday, I went after the Center shopping before some friends, I really enjoyed it, I liked to buy new clothes for me, it's my best hobbie, the problem is that I don't have so much money now, I think I'll ask for it despite my father, I need more clothes, I'm planning to go back to the shopping again tomorrow, maybe today beyond the afternoon. |\n",
        "| DPO          | Yesterday I went after the Center shopping before some friends, I really enjoyed it, I liked to buy new clothes for me, it's my best hobbie, the problem is that I doesn't have so much money now, I think I'll ask for it despite my father, I need more clothes, I'm planning to go again tomorrow, maybe today beyond the afternoon.        |\n",
        "| rDPO         | Yesterday I went after the Center shopping before some friends, I really enjoyed it, I liked to buy new clothes for me, it's my best hobbie, the problem is that I doesn't have so much money now, I think I'll ask for it despite my father, I need more clothes, I'm planning to go of the shopping again tomorrows, maybe today beyond the afternoon.     |\n",
        "| **Sample 5 Preference** |      SFT                                                                                                                                                                                                                                                        |\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- Discussion:\n",
        "\n",
        "    (Discuss the role of any changes in achieving these results. Consider potential trade-offs or limitations introduced by the new approach.)\n",
        "\n",
        "    - The bleu score increase from DPO to robust DPO, as well as the qualitative case analysis shows that he Robust DPO is more applicable when it comes to DPO datasets with a high preferential noise level, which is the case of the current preference dataset. By adding label_smoothing=0.3 to adjust the loss function to account for preferential noise, SFT + robust DPO obtains the highest score in BLEU evaluation.\n",
        "    - As mentioned early, the current project suffers from several aspects along different stages, pending further improvement:\n",
        "        - using bleu score as the sole evaluation metric for the grammatical correction task, which is not the best metric to capture grammatical nuances;\n",
        "        - using edit distance as the annotating tool for preference datase;\n",
        "        - experimenting with more decoding strategies and apprpaches to elicit diverse generations.\n",
        "    - Most of the tradeoff discussions have been covered in early discussions in Part 2. In general, computational efficiecny, model performance (in the current criteria of BLEU score) are the ultimate key factors in consideration."
      ],
      "metadata": {
        "id": "ylnjRCa2ZfQO"
      }
    }
  ]
}